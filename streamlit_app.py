import streamlit as st
import pandas as pd
import numpy as np
import joblib, os, json, runpy, shap
import matplotlib.pyplot as plt
import seaborn as sns

import plotly.express as px
import plotly.figure_factory as ff
import plotly.graph_objects as go

from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, roc_curve, auc, precision_recall_curve, roc_auc_score
)
from sklearn.inspection import PartialDependenceDisplay
from sklearn.model_selection import train_test_split, learning_curve
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostClassifier

# ==============================
# ==============================
# CONFIG
# ==============================
st.set_page_config(page_title="Parkinsonâ€™s ML App", page_icon="ğŸ§ ", layout="wide")

# ==============================
# Sidebar Settings
# ==============================
st.sidebar.title("âš™ï¸ Settings")

# âœ… Theme selector
theme_choice = st.sidebar.radio("Theme", ["Light", "Dark"], index=0, key="theme_choice")

# âœ… Language selector
language_choice = st.sidebar.selectbox(
    "Language", ["English", "×¢×‘×¨×™×ª", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "FranÃ§ais"], index=1, key="lang_choice"
)

# âœ… Text size
text_size = st.sidebar.select_slider(
    "Text Size", options=["Small", "Medium", "Large"], value="Medium", key="text_size"
)

# âœ… Layout density
layout_density = st.sidebar.radio(
    "Layout Density", ["Comfortable", "Compact"], index=0, key="layout_density"
)

# âœ… Toggle advanced EDA
show_advanced_eda = st.sidebar.checkbox(
    "Show Advanced EDA Visualizations", value=True, key="eda_toggle"
)

# âœ… Decision Threshold (global) â†’ ××—×“ ×‘×œ×‘×“
threshold_global = st.sidebar.slider(
    "Decision Threshold (Global)", 0.0, 1.0, 0.5, 0.01, key="global_threshold"
)
# Demo Mode
demo_mode = st.sidebar.checkbox("Enable Demo Mode (load sample data)", value=False, key="demo_mode")

# Dataset Handling
dataset_mode = st.sidebar.radio(
    "Dataset Mode",
    ["Use Default Dataset", "Replace with Uploaded", "Merge with Uploaded"],
    index=0,
    key="dataset_mode"
)

# ==============================
# Apply UI Customizations (CSS)
# ==============================
def apply_custom_style():
    css = ""
    # Theme
    if theme_choice == "Dark":
        css += """
        body, .stApp {
            background-color: #111 !important;
            color: #eee !important;
        }
        """
    # Text size
    if text_size == "Small":
        css += "body, .stApp { font-size: 13px !important; }"
    elif text_size == "Medium":
        css += "body, .stApp { font-size: 16px !important; }"
    elif text_size == "Large":
        css += "body, .stApp { font-size: 19px !important; }"

    # Layout density
    if layout_density == "Compact":
        css += ".block-container { padding-top: 0rem; padding-bottom: 0rem; }"

    st.markdown(f"<style>{css}</style>", unsafe_allow_html=True)

apply_custom_style()


# ==============================
# Helpers
# ==============================
def align_features(model, X: pd.DataFrame) -> pd.DataFrame:
    """××ª××™× ××ª ×”×§×•×‘×¥ ×©×”×•×¢×œ×” ×œ×¢××•×“×•×ª ×©×”××•×“×œ ××¦×¤×” ×œ×”×Ÿ"""
    if hasattr(model, "feature_names_in_"):
        expected_cols = list(model.feature_names_in_)
        # × ×•×¡×™×£ ×¢××•×“×•×ª ×—×¡×¨×•×ª
        for col in expected_cols:
            if col not in X.columns:
                X[col] = 0
        # × ×¡×™×¨ ×¢××•×“×•×ª ×¢×•×“×¤×•×ª ×•× ×©××•×¨ ×¢×œ ×¡×“×¨
        X = X[expected_cols]
    return X

def safe_predict(model, X):
    try:
        return model.predict(X)
    except Exception:
        X = align_features(model, X)
        return model.predict(X)

def safe_predict_proba(model, X):
    try:
        return model.predict_proba(X)
    except Exception:
        X = align_features(model, X)
        return model.predict_proba(X)


# ==============================
# Load dataset
# ==============================
DATA_PATH = "data/parkinsons.csv"
df = pd.read_csv(DATA_PATH)
if demo_mode:
    st.info("Demo Mode Enabled â€“ using sample dataset âœ…")
    df = pd.read_csv(DATA_PATH).sample(50, random_state=42)  # ×ª×ª-×¡×˜ ×§×˜×Ÿ ×œ×”×“×’××”
else:
    df = pd.read_csv(DATA_PATH)

X = df.drop("status", axis=1)
y = df["status"]

# ==============================
# Load model + metrics
# ==============================
def load_model_and_metrics():
    if not os.path.exists("models/best_model.joblib") or not os.path.exists("assets/metrics.json"):
        runpy.run_path("app/model_pipeline.py")
    best_model = joblib.load("models/best_model.joblib")
    with open("assets/metrics.json","r") as f:
        metrics = json.load(f)
    return best_model, metrics

if "best_model" not in st.session_state or "metrics" not in st.session_state:
    st.session_state.best_model, st.session_state.metrics = load_model_and_metrics()

best_model = st.session_state.best_model
metrics = st.session_state.metrics

# Model Last Updated
last_updated_path = "assets/last_updated.txt"
if os.path.exists(last_updated_path):
    with open(last_updated_path, "r") as f:
        last_updated = f.read().strip()
else:
    last_updated = "Unknown"

st.sidebar.markdown(f"ğŸ•’ **Model Last Updated:** {last_updated}")

# ==============================
# Tabs
# ==============================
tab1, tab_dash, tab2, tab3, tab5, tab4, tab_hist, tab_explain, tab_about, tab_qa = st.tabs([
    "ğŸ“Š Data & EDA", 
    "ğŸ“ˆ Dashboard",
    "ğŸ¤– Models", 
    "ğŸ”® Prediction", 
    "ğŸ§ª Test Evaluation",
    "âš¡ Train New Model",
    "ğŸ•‘ Model History",
    "ğŸ§  Explainability",
    "â„¹ï¸ About",
    "â“ Q&A"   
])


# --- Tab 1: Data & EDA ---
with tab1:
    st.header("ğŸ“Š Data & Exploratory Data Analysis")
    st.header("ğŸ“Š Data & EDA")
    with st.expander("â„¹ï¸ ××” ×ª××¦××• ×›××Ÿ?"):
        st.markdown("""
        ×‘×œ×©×•× ×™×ª ×–×• ××•×¦×’ × ×™×ª×•×— ×”× ×ª×•× ×™× ×”×’×•×œ××™×™× (EDA).  
        ×ª×•×›×œ×• ×œ×¨××•×ª ×”×ª×¤×œ×’×•×™×•×ª, ×¡×˜×˜×™×¡×˜×™×§×•×ª ×‘×¡×™×¡×™×•×ª, ××ª×××™× (Heatmap), 
        ×•-PCA ×©××¨××” ×›×™×¦×“ × ×™×ª×Ÿ ×œ×”×‘×—×™×Ÿ ×‘×™×Ÿ ×—×•×œ×™× ×œ×‘×¨×™××™×.
        """)

    st.subheader("Dataset Preview")
    st.dataframe(df.head())

    st.subheader("Dataset Info & Statistics")
    st.write(f"ğŸ”¹ Rows: {df.shape[0]}, Columns: {df.shape[1]}")

    missing = df.isnull().sum()
    if missing.sum() > 0:
        st.warning("Missing Values detected:")
        st.dataframe(missing[missing > 0])
    else:
        st.success("No missing values âœ…")

    st.dataframe(df.describe().T)
    st.table(y.value_counts().rename({0: "Healthy", 1: "Parkinsonâ€™s"}))

    st.write("ğŸ”¹ Top Features Correlated with Target")
    corr_target = df.corr()["status"].abs().sort_values(ascending=False)[1:6]
    st.table(corr_target)

    st.subheader("Exploratory Plots")
    eda_dir = "eda"
    eda_plots = {
        "Target Distribution (Count & Pie)": "target_distribution_combo.png",
        "Correlation Heatmap": "corr_heatmap.png",
        "Pairplot of Top Features": "pairplot_top_features.png",
        "Histograms & Violin Plots": "distributions_violin.png",
        "PCA Projection": "pca.png",
        "t-SNE Projection": "tsne.png"
    }

    for title, filename in eda_plots.items():
        path = os.path.join(eda_dir, filename)
        if os.path.exists(path):
            with st.expander(title, expanded=False):
                st.image(path, use_column_width=True)

    # ğŸ“Œ ×”×¡×‘×¨×™× ×˜×§×¡×˜×•××œ×™×™×
    st.header("ğŸ“Š Data & Exploratory Data Analysis - Explanation")
    with st.expander("ğŸ“‚ Dataset Overview"):
        st.markdown("""
        ×”×“××˜×” ×©×œ× ×• ××’×™×¢ ×Ö¾**UCI Parkinsonâ€™s Dataset** â€“ ×××’×¨ ××—×§×¨×™ ××‘×•×¡×¡ ×•××•×›×¨.  
        ×™×© ×‘×• **195 ×“×’×™××•×ª** ×‘×œ×‘×“, ×¢× **23 ×××¤×™×™× ×™× ×§×•×œ×™×™×** ×©× ××“×“×• ×× ×‘×“×§×™× (×—×•×œ×™× ×•×‘×¨×™××™×).  

        - **×¢××•×“×ª ×™×¢×“:** `status` (0=×‘×¨×™×, 1=×—×•×œ×”).  
        - **××ª×’×¨ ××¨×›×–×™:** ×—×•×¡×¨ ××™×–×•×Ÿ â€“ ×›Ö¾75% ××”×“×’×™××•×ª ×”×Ÿ ×©×œ ×—×•×œ×™× ×•×¨×§ ×›Ö¾25% ×©×œ ×‘×¨×™××™×.  

        âš ï¸ ×”××©××¢×•×ª: ××•×“×œ × ××™×‘×™ ×©×× ×‘× ×ª××™×“ "×—×•×œ×”" ×™×©×™×’ Accuracy ×’×‘×•×” â€“ ××‘×œ ×œ× ×‘×××ª ×™×”×™×” ×©×™××•×©×™.  
        ×œ×›×Ÿ ×”×—×œ×˜× ×• ×œ×”×¡×ª××š ×’× ×¢×œ ××“×“×™× ××ª×§×“××™× ×™×•×ª×¨: **Recall, Precision, F1, ROC-AUC**.
        """)

    with st.expander("ğŸ” Key Features"):
        st.markdown("""
        - **Jitter** â€“ ×©×•× ×•×ª ×§×˜× ×” ×‘×ª×“×¨ ×”×“×™×‘×•×¨; ××¦×œ ×—×•×œ×™× ×™×© ×¨×¢×™×“×•×ª ×—×–×§×•×ª ×™×•×ª×¨.  
        - **Shimmer** â€“ ×©×•× ×•×ª ×‘×¢×•×¦××ª ×”×§×•×œ; ××¦×œ ×—×•×œ×™× × ×¦×¤×ª×” ×—×•×¡×¨ ×™×¦×™×‘×•×ª ×’×‘×•×”.  
        - **Fo (Fundamental Frequency)** â€“ ×”×ª×“×¨ ×”×‘×¡×™×¡×™; ××¦×œ ×—×•×œ×™× ×¤×—×•×ª ×™×¦×™×‘.  
        - **NHR (Noise-to-Harmonics Ratio)** â€“ ×™×—×¡ ×¨×¢×© ×œ×”×¨××•× ×™×•×ª; ××¦×œ ×—×•×œ×™× ×”×¢×¨×›×™× ×’×‘×•×”×™× ×™×•×ª×¨.  

        ğŸ“Œ ××œ×• ××©×ª× ×™× ×©× ×‘×“×§×• ×¨×‘×•×ª ×‘××—×§×¨ ×§×œ×™× ×™ ×•×”× ×¡×× ×™× ××•×›×¨×™× ×œ×¤×¨×§×™× ×¡×•×Ÿ â€“ ×—×™×–×•×§ ×œ×›×š ×©×”×“××˜×” ××™×›×•×ª×™.
        """)
    with st.expander("ğŸ” ×”×¡×‘×¨ ×¢×œ ×’×¨×£ PCA"):
    st.markdown("""
    ×’×¨×£ ×–×” ××¦×™×’ ××ª ×”×§×¨× ×ª ×”× ×ª×•× ×™× ×œ×“×•Ö¾×××“ ×‘×××¦×¢×•×ª PCA (Principal Component Analysis).

    **××” ×¨×•××™× ×›××Ÿ?**  
    - ×›×œ × ×§×•×“×” ××™×™×¦×’×ª × ×‘×“×§.  
    - ×™×¨×•×§ (`0`) = ×‘×¨×™×.  
    - ×›×ª×•× (`1`) = ×—×•×œ×” ×¤×¨×§×™× ×¡×•×Ÿ.  
    - ×”×¦×™×¨×™× ×”× ×¨×›×™×‘×™× ×¨××©×™×™× (×©×™×œ×•×‘×™× ×©×œ ×›×œ ×”×¤×™×¦â€™×¨×™×).

    **×œ××” ×¢×•×©×™× PCA?**  
    - ×›×“×™ ×œ×”×§×˜×™×Ÿ ×××“×™× (×™×© ×¢×©×¨×•×ª ×¤×™×¦â€™×¨×™×).  
    - ×××¤×©×¨ ×œ×¨××•×ª ×‘×¢×™× ×™×™× ×”×× ×™×© ×”×‘×“×œ ×‘×™×Ÿ ×—×•×œ×™× ×œ×‘×¨×™××™×.  
    - ××’×œ×” ××‘× ×” ×¤× ×™××™ ×‘× ×ª×•× ×™× (×§×œ××¡×˜×¨×™×, ××’××•×ª, ×¨×¢×©).

    **××” ××¤×©×¨ ×œ×”×¡×™×§ ××”×’×¨×£?**  
    1. ×™×© ×—×¤×™×¤×” ×‘×™×Ÿ ×”×§×‘×•×¦×•×ª â†’ ××¡×‘×™×¨ ×œ××” ×”××•×“×œ×™× ×œ× ××’×™×¢×™× ×œÖ¾100% ×“×™×•×§.  
    2. ×™×© ××–×•×¨×™× ×©×‘×”× ×™×© ×”×¤×¨×“×” ×˜×•×‘×” ×™×•×ª×¨ (×—×•×œ×™× ××•×œ ×‘×¨×™××™×).  
    3. ×§×™×™××™× Outliers â€“ × ×§×•×“×•×ª ×—×¨×™×’×•×ª ×©× ××¦××•×ª ×¨×—×•×§ ××”×¢× ×Ÿ ×”××¨×›×–×™.

    **××¡×§× ×•×ª:**  
    - ×”×“××˜×” ×œ× ××•×¤×¨×“ ×‘×¦×•×¨×” × ×§×™×™×” â†’ × ×“×¨×© ××•×“×œ ×—×›× ×›××• XGBoost.  
    - PCA ×›×Ÿ ×”×¨××” ×©×™×© ××‘× ×” ×¤× ×™××™ ×××™×ª×™, ×›×œ×•××¨ ×”×”×‘×“×œ×™× ×‘×§×•×œ ××©××¢×•×ª×™×™×.  
    - × ×§×•×“×•×ª ×—×¨×™×’×•×ª ××–×›×™×¨×•×ª ×œ× ×• ×œ×‘×“×•×§ ××™×›×•×ª ×“××˜×”.  
    """)
    with st.expander("ğŸ” ×”×¡×‘×¨ ×¢×œ ×’×¨×£ t-SNE"):
    st.markdown("""
    ×’×¨×£ ×–×” ××¦×™×’ ××ª ×”×§×˜× ×ª ×”×××“×™× ×‘×××¦×¢×•×ª t-SNE (t-distributed Stochastic Neighbor Embedding).

    **××” ×–×” t-SNE?**  
    - ×©×™×˜×” ×œ×Ö¾×œ×™× ×™××¨×™×ª ×©××¦×™×’×” ×§×¨×‘×” ×‘×™×Ÿ × ×§×•×“×•×ª.  
    - ××¨××” ×‘×¦×•×¨×” ×˜×•×‘×” ×™×•×ª×¨ ×§×œ××¡×˜×¨×™× (×§×‘×•×¦×•×ª ×“×•××•×ª).  

    **××” ×¨×•××™× ×‘×’×¨×£?**  
    - ×™×¨×•×§ = ×‘×¨×™×, ×›×ª×•× = ×—×•×œ×” ×¤×¨×§×™× ×¡×•×Ÿ.  
    - ×™×© ×§×œ××¡×˜×¨×™× ×‘×¨×•×¨×™× ×™×•×ª×¨ ×××©×¨ ×‘-PCA.  
    - ×¢×“×™×™×Ÿ ×§×™×™××ª ×—×¤×™×¤×” ××¡×•×™××ª.

    **××¡×§× ×•×ª:**  
    1. t-SNE ××¨××” ×§×‘×•×¦×•×ª ××•×‘×—× ×•×ª ×™×•×ª×¨ ×©×œ ×—×•×œ×™× ××•×œ ×‘×¨×™××™×.  
    2. ×™×© ×¢×“×™×™×Ÿ ×—×¤×™×¤×” â€“ ××¡×‘×™×¨ ×œ××” ××™×Ÿ ×“×™×•×§ ××•×—×œ×˜ ×‘××•×“×œ×™×.  
    3. ×”×˜×›× ×™×§×” ×—×©×¤×” ××‘× ×™× ×¤× ×™××™×™× ××¢× ×™×™× ×™× â€“ ×ª×ª×™-×§×‘×•×¦×•×ª ×©×•× ×•×ª.  

    ğŸ‘‰ ×™×—×“ ×¢× PCA, ×–×” ××—×–×§ ××ª ×”×”×‘× ×” ×©×”×§×•×œ ××›×™×œ ××™×“×¢ ×—×–×§ ×œ× ×™×‘×•×™ ×¤×¨×§×™× ×¡×•×Ÿ.
    """)
    st.pyplot(heatmap_fig)

with st.expander("ğŸ” ×”×¡×‘×¨ ×¢×œ Heatmap (××¤×ª ××ª×××™×)"):
    st.markdown("""
    Heatmap ××¦×™×’ ××ª ×”××ª×× (Correlation) ×‘×™×Ÿ ×›×œ ×–×•×’ ×¤×™×¦â€™×¨×™×.

    **××” ×–×” ××ª××?**  
    - ×¢×¨×š ×‘×™×Ÿ -1 ×œ-1.  
    - ×¢×¨×š ×—×™×•×‘×™ ×’×‘×•×” â†’ ×©× ×™ ×”×¤×™×¦â€™×¨×™× ×¢×•×œ×™× ×™×—×“.  
    - ×¢×¨×š ×©×œ×™×œ×™ ×’×‘×•×” â†’ ××—×“ ×¢×•×œ×” ×•×”×©× ×™ ×™×•×¨×“.  
    - ×¢×¨×š ×§×¨×•×‘ ×œ-0 â†’ ××™×Ÿ ×§×©×¨.

    **××” ××¦×× ×•?**  
    - Jitter ×•-Shimmer ××ª×•×××™× ×—×–×§ ×–×” ×¢× ×–×”.  
    - Spread1 ×•-PPE ××ª×•×××™× ×—×–×§ ×¢× ×”×¡×˜×˜×•×¡ (×—×•×œ×”/×‘×¨×™×).  
    - ×™×© ×¤×™×¦â€™×¨×™× ×¢× ××ª×× ×’×‘×•×” â†’ ××” ×©××¢×™×“ ×¢×œ ×¢×•×“×£ ××™×“×¢, ×•×¦×¨×™×š ×œ×”×™×–×”×¨ ×-Overfitting.

    **××¡×§× ×”:**  
    Heatmap ×¢×•×–×¨ ×œ× ×• ×œ×‘×—×•×¨ ××™×œ×• ×¤×™×¦â€™×¨×™× ×œ×©××•×¨ ×œ××•×“×œ, ×•××™×œ×• ××¤×©×¨ ×œ×•×•×ª×¨ ×›×“×™ ×œ×× ×•×¢ ×›×¤×™×œ×•×™×•×ª.
    """)




    with st.expander("ğŸ“Š EDA Findings"):
        st.markdown("""
        - **Heatmap:** ××¦×× ×• ×§×©×¨ ××•×‘×”×§ ×‘×™×Ÿ jitter/shimmer ×œ×‘×™×Ÿ ××¦×‘ ×”××—×œ×”.  
        - **PCA:** ×’× ×›×©×¦××¦×× ×• ×œÖ¾2 ×¨×›×™×‘×™× ×‘×œ×‘×“, ×¢×“×™×™×Ÿ × ×¨××ª×” ×”×¤×¨×“×” ×˜×•×‘×” ×‘×™×Ÿ ×—×•×œ×™× ×œ×‘×¨×™××™×.  
        - **t-SNE:** ×”×¨××” ××©×›×•×œ×•×ª ×‘×¨×•×¨×™× â€“ ×—×•×œ×™× ××ª×¨×›×–×™× ×‘××–×•×¨ ××•×’×“×¨.  
        - **Violin + Histogram:** jitter ×•Ö¾shimmer ×‘×¢×œ×™ ×©×•× ×•×ª ×’×‘×•×”×” ×××•×“ ××¦×œ ×—×•×œ×™× ×œ×¢×•××ª ×‘×¨×™××™×.  

        ğŸ‘‰ **××¡×§× ×”:** ×œ××¨×•×ª ×’×•×“×œ ×”×“××˜×” ×”×§×˜×Ÿ, ×”×¡×™×’× ×œ ×—×–×§ ×××•×“ â€“ ××” ×©××¤×©×¨ ×œ× ×• ×œ×”××©×™×š ×‘×‘×™×˜×—×•×Ÿ ×œ×‘× ×™×™×ª ××•×“×œ×™×.
        """)

       
# --- Tab 2: Dashboard         
with tab_dash:
    st.header("ğŸ“ˆ Interactive Dashboard â€“ Compare Models")
    with st.expander("â„¹ï¸ ××” ×ª××¦××• ×›××Ÿ?"):
        st.markdown("""
        ×‘×œ×©×•× ×™×ª ×–×• ××•×¦×’ ×œ×•×— ××—×•×•× ×™× ××™× ×˜×¨××§×˜×™×‘×™ ×¢× ××“×“×™× ××¨×›×–×™×™×.  
        ×›××Ÿ × ×™×ª×Ÿ ×œ×¢×§×•×‘ ××—×¨×™ ×‘×™×¦×•×¢×™ ×”××•×“×œ×™×, ×œ×¨××•×ª KPIâ€™s ×•×’×¨×¤×™× ××¡×›××™× 
        ×‘×¦×•×¨×” ××¨×•×›×–×ª ×•× ×•×—×”.
        """)

    # --- ×‘×—×™×¨×ª ××•×“×œ×™× ---
    model_options = [
        "LogisticRegression","RandomForest","SVM",
        "KNN","XGBoost","LightGBM","CatBoost","NeuralNet"
    ]
    chosen_models = st.multiselect(
        "×‘×—×¨ ××•×“×œ×™× ×œ×”×©×•×•××”", 
        model_options, 
        default=["RandomForest","XGBoost"]
    )
    
    # --- ×”×™×¤×¨-×¤×¨××˜×¨×™× ---
    st.subheader("âš™ï¸ Hyperparameters")
    params = {}

    if "LogisticRegression" in chosen_models:
        params["LogisticRegression"] = {
            "C": st.slider("LogReg: Regularization C", 0.01, 10.0, 1.0, 0.1, key="logreg_c_dash"),
            "max_iter": st.slider("LogReg: Max Iterations", 100, 2000, 500, 100, key="logreg_iter_dash")
        }

    if "RandomForest" in chosen_models:
        params["RandomForest"] = {
            "n_estimators": st.slider("RF: Number of Trees", 50, 500, 200, 50, key="rf_trees_dash"),
            "max_depth": st.slider("RF: Max Depth", 2, 20, 5, key="rf_depth_dash"),
            "min_samples_split": st.slider("RF: Min Samples Split", 2, 20, 2, key="rf_split_dash"),
            "min_samples_leaf": st.slider("RF: Min Samples Leaf", 1, 20, 1, key="rf_leaf_dash")
        }

    if "XGBoost" in chosen_models:
        params["XGBoost"] = {
            "learning_rate": st.slider("XGB: Learning Rate", 0.01, 0.5, 0.1, 0.01, key="xgb_lr_dash"),
            "n_estimators": st.slider("XGB: Estimators", 50, 500, 200, 50, key="xgb_estimators_dash"),
            "max_depth": st.slider("XGB: Max Depth", 2, 20, 6, key="xgb_depth_dash"),
            "subsample": st.slider("XGB: Subsample", 0.5, 1.0, 1.0, 0.05, key="xgb_subsample_dash"),
            "colsample_bytree": st.slider("XGB: Colsample by Tree", 0.5, 1.0, 1.0, 0.05, key="xgb_colsample_dash")
        }

    if "LightGBM" in chosen_models:
        params["LightGBM"] = {
            "n_estimators": st.slider("LGBM: Estimators", 50, 500, 200, 50, key="lgb_estimators_dash"),
            "learning_rate": st.slider("LGBM: Learning Rate", 0.01, 0.5, 0.1, 0.01, key="lgb_lr_dash"),
            "num_leaves": st.slider("LGBM: Num Leaves", 10, 200, 31, key="lgb_leaves_dash"),
            "max_depth": st.slider("LGBM: Max Depth", -1, 20, -1, key="lgb_depth_dash")
        }

    if "CatBoost" in chosen_models:
        params["CatBoost"] = {
            "iterations": st.slider("CatBoost: Iterations", 100, 2000, 500, 100, key="cat_iters_dash"),
            "depth": st.slider("CatBoost: Depth", 2, 12, 6, key="cat_depth_dash"),
            "learning_rate": st.slider("CatBoost: Learning Rate", 0.01, 0.5, 0.1, 0.01, key="cat_lr_dash")
        }

    if "SVM" in chosen_models:
        params["SVM"] = {
            "C": st.slider("SVM: Regularization C", 0.01, 10.0, 1.0, 0.1, key="svm_c_dash"),
            "kernel": st.selectbox("SVM: Kernel", ["rbf", "linear", "poly"], index=0, key="svm_kernel_dash"),
            "gamma": st.selectbox("SVM: Gamma", ["scale", "auto"], index=0, key="svm_gamma_dash")
        }

    if "KNN" in chosen_models:
        params["KNN"] = {
            "n_neighbors": st.slider("KNN: Neighbors", 1, 20, 5, key="knn_neighbors_dash"),
            "weights": st.selectbox("KNN: Weights", ["uniform", "distance"], index=0, key="knn_weights_dash")
        }

    if "NeuralNet" in chosen_models:
        params["NeuralNet"] = {
            "hidden_layer_sizes": st.text_input("NN: Hidden Layers (comma-separated)", "64,32", key="nn_layers_dash"),
            "activation": st.selectbox("NN: Activation", ["relu", "tanh", "logistic"], index=0, key="nn_activation_dash"),
            "max_iter": st.slider("NN: Max Iterations", 100, 2000, 500, 100, key="nn_iter_dash")
        }

    # --- ×”×¤×¢×œ×” ---
    if st.button("ğŸš€ Run Comparison"):
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        trained_models = {}
        metrics_comp = {}

        for m in chosen_models:
            model = None

            if m == "LogisticRegression":
                model = Pipeline([
                    ("scaler", StandardScaler()),
                    ("clf", LogisticRegression(
                        C=params[m]["C"],
                        max_iter=params[m]["max_iter"]
                    ))
                ])
            elif m == "RandomForest":
                model = RandomForestClassifier(
                    n_estimators=params[m]["n_estimators"],
                    max_depth=params[m]["max_depth"],
                    min_samples_split=params[m]["min_samples_split"],
                    min_samples_leaf=params[m]["min_samples_leaf"],
                    random_state=42
                )
            elif m == "XGBoost":
                model = xgb.XGBClassifier(
                    eval_metric="logloss",
                    n_estimators=params[m]["n_estimators"],
                    learning_rate=params[m]["learning_rate"],
                    max_depth=params[m]["max_depth"],
                    subsample=params[m]["subsample"],
                    colsample_bytree=params[m]["colsample_bytree"],
                    random_state=42
                )
            elif m == "LightGBM":
                model = lgb.LGBMClassifier(
                    n_estimators=params[m]["n_estimators"],
                    learning_rate=params[m]["learning_rate"],
                    num_leaves=params[m]["num_leaves"],
                    max_depth=params[m]["max_depth"],
                    random_state=42
                )
            elif m == "CatBoost":
                model = CatBoostClassifier(
                    iterations=params[m]["iterations"],
                    depth=params[m]["depth"],
                    learning_rate=params[m]["learning_rate"],
                    verbose=0,
                    random_state=42
                )
            elif m == "SVM":
                model = Pipeline([
                    ("scaler", StandardScaler()),
                    ("clf", SVC(
                        C=params[m]["C"],
                        kernel=params[m]["kernel"],
                        gamma=params[m]["gamma"],
                        probability=True
                    ))
                ])
            elif m == "KNN":
                model = Pipeline([
                    ("scaler", StandardScaler()),
                    ("clf", KNeighborsClassifier(
                        n_neighbors=params[m]["n_neighbors"],
                        weights=params[m]["weights"]
                    ))
                ])
            elif m == "NeuralNet":
                hidden_layers = tuple(map(int, params[m]["hidden_layer_sizes"].split(",")))
                model = Pipeline([
                    ("scaler", StandardScaler()),
                    ("clf", MLPClassifier(
                        hidden_layer_sizes=hidden_layers,
                        activation=params[m]["activation"],
                        max_iter=params[m]["max_iter"],
                        random_state=42
                    ))
                ])

            # --- ××™××•×Ÿ ×•×”×¢×¨×›×ª ×‘×™×¦×•×¢×™× ---
            if model is not None:
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                y_proba = model.predict_proba(X_test)[:, 1]

                acc = accuracy_score(y_test, y_pred)
                prec = precision_score(y_test, y_pred)
                rec = recall_score(y_test, y_pred)
                f1 = f1_score(y_test, y_pred)
                auc_val = roc_auc_score(y_test, y_proba)

                trained_models[m] = model
                metrics_comp[m] = {
                    "accuracy": acc,
                    "precision": prec,
                    "recall": rec,
                    "f1": f1,
                    "roc_auc": auc_val
                }

        # --- ×˜×‘×œ×ª ×”×©×•×•××” ---
        st.subheader("ğŸ“Š Metrics Comparison")
        df_comp = pd.DataFrame(metrics_comp).T.sort_values("roc_auc", ascending=False)
        df_comp.insert(0, "Rank", range(1, len(df_comp)+1))
        df_comp_display = df_comp.copy()
        df_comp_display.iloc[0, df_comp_display.columns.get_loc("Rank")] = "ğŸ† 1"
        st.dataframe(df_comp_display)

        # --- ROC Curves ---
        st.subheader("ROC Curves")
        fig = go.Figure()
        for m, model in trained_models.items():
            y_proba = model.predict_proba(X_test)[:,1]
            fpr, tpr, _ = roc_curve(y_test, y_proba)
            fig.add_trace(go.Scatter(x=fpr, y=tpr, mode="lines", name=f"{m} (AUC={metrics_comp[m]['roc_auc']:.2f})"))
        fig.add_trace(go.Scatter(x=[0,1], y=[0,1], mode="lines", line=dict(dash="dash"), name="Random"))
        st.plotly_chart(fig, use_container_width=True)
        st.pyplot(roc_fig)

        # --- Precision-Recall Curves ---
        st.subheader("Precision-Recall Curves")
        fig = go.Figure()
        for m, model in trained_models.items():
            y_proba = model.predict_proba(X_test)[:,1]
            prec, rec, _ = precision_recall_curve(y_test, y_proba)
            fig.add_trace(go.Scatter(x=rec, y=prec, mode="lines", name=m))
            st.plotly_chart(fig, use_container_width=True) 
            st.header("ğŸ¤– Models & Results")
            
    st.header("Models Explanation")
    with st.expander("ğŸ“Œ Logistic Regression"):
        st.markdown("""
        ××•×“×œ ×œ×™× ×™××¨×™ ×¤×©×•×˜ ×©××©××© ×›×§×• ×‘×¡×™×¡.  
        - **×ª×•×¦××” ××¦×œ× ×•:** ROC-AUC â‰ˆ 0.85.  
        - **×‘×¢×™×”:** ×”×¨×‘×” False Positives (×‘×¨×™××™× ×©×–×•×”×• ×›×—×•×œ×™×).  
        - **××¡×§× ×”:** ×œ× ××ª××™× ×œ×©×™××•×© ×¨×¤×•××™, ××‘×œ ×˜×•×‘ ×›×‘×¡×™×¡ ×œ×”×©×•×•××”.  
        """)

    with st.expander("ğŸŒ² Random Forest"):
        st.markdown("""
        Ensemble ×©×œ ×¢×¦×™ ×”×—×œ×˜×” â€“ ×›×œ ×¢×¥ "××¦×‘×™×¢" ×¢×œ ×ª×—×–×™×ª ×¡×•×¤×™×ª.  
        - **×ª×•×¦××”:** ROC-AUC â‰ˆ 0.90.  
        - GridSearchCV ×©×™×¤×¨ ×¤×¨××˜×¨×™× ×›××• `n_estimators`, `max_depth`.  
        - **×™×ª×¨×•×Ÿ:** ×™×¦×™×‘ ×•××¡×‘×™×¨ (Feature Importance).  
        - **×—×™×¡×¨×•×Ÿ:** ×¤×—×•×ª ×—×“ ×‘×”×©×•×•××” ×œÖ¾boosting.  
        """)

    with st.expander("âš¡ SVM"):
        st.markdown("""
        ××•×“×œ ×©××—×¤×© ××ª ×”××¤×¨×™×“ ×”×˜×•×‘ ×‘×™×•×ª×¨ ×‘×™×Ÿ ×”×§×‘×•×¦×•×ª ×¢× "××¨×•×•×— ××§×¡×™××œ×™".  
        - **×ª×•×¦××” ××¦×œ× ×•:** ROC-AUC â‰ˆ 0.88.  
        - **×™×ª×¨×•×Ÿ:** ××¦×•×™×Ÿ ×‘×“××˜×” ×§×˜×Ÿ.  
        - **×—×™×¡×¨×•×Ÿ:** ××ª×§×©×” ×‘××‘× ×™× ××•×¨×›×‘×™×.  
        """)

    with st.expander("ğŸ‘¥ KNN"):
        st.markdown("""
        ××¡×•×•×’ ×“×’×™××” ×—×“×©×” ×œ×¤×™ ×§×¨×‘×ª×” ×œ×©×›× ×™× ×”×§×¨×•×‘×™× ×‘×™×•×ª×¨.  
        - **×ª×•×¦××”:** ROC-AUC â‰ˆ 0.82 (×”×—×œ×© ×‘×™×•×ª×¨).  
        - **×—×™×¡×¨×•×Ÿ:** ×¨×’×™×© ×××•×“ ×œ×¨×¢×© ×•×“××˜×” ×§×˜×Ÿ.  
        - **××¡×§× ×”:** ×œ× ××ª××™× ×œ×‘×¢×™×” ×–×•.  
        """)

    with st.expander("â­ XGBoost"):
        st.markdown("""
        ××œ×’×•×¨×™×ª× Gradient Boosting ××”×—×–×§×™× ×‘×™×•×ª×¨.  
        - **×ª×•×¦××”:** ROC-AUC â‰ˆ 0.94 â†’ ×”××•×“×œ ×”×× ×¦×—.  
        - GridSearchCV ×©×™×¤×¨ `learning_rate`, `max_depth`, `subsample`.  
        - **×™×ª×¨×•×Ÿ ×§×¨×™×˜×™:** ×›××¢×˜ ×•××™×Ÿ False Negatives â†’ ×œ× ××¤×¡×¤×¡ ×—×•×œ×™× ×××™×ª×™×™×.  
        """)

    with st.expander("ğŸš€ LightGBM"):
        st.markdown("""
        ×’×¨×¡×” ×™×¢×™×œ×” ×•××”×™×¨×” ×©×œ boosting.  
        - **×ª×•×¦××”:** ROC-AUC â‰ˆ 0.93.  
        """)

    with st.expander("ğŸ± CatBoost"):
        st.markdown("""
        ××•×ª×× ×‘××™×•×—×“ ×œ×“××˜×” ×œ× ×××•×–×Ÿ ×›××• ×©×œ× ×•.  
        - **×ª×•×¦××”:** ROC-AUC â‰ˆ 0.93.  
        """)

    with st.expander("ğŸ§  NeuralNet (MLP)"):
        st.markdown("""
        ×¨×©×ª × ×•×™×¨×•× ×™× ×¢× ×©×›×‘×•×ª ××œ××•×ª.  
        - **×ª×•×¦××”:** ROC-AUC â‰ˆ 0.87.  
        - **×‘×¢×™×”:** ×“××˜×” ×§×˜×Ÿ â†’ ×¨×©×ª ×œ× ×™×¦×™×‘×” ×•×œ× ×¢×§×¤×” boosting.  
        """)
        

# --- Tab 3: Models
with tab2:
    st.header("ğŸ¤– Model Training & Comparison")
    with st.expander("â„¹ï¸ ××” ×ª××¦××• ×›××Ÿ?"):
        st.markdown("""
        ×›××Ÿ ××•×¦×’×™× ×›×œ ×”××•×“×œ×™× ×©××™×× ×•: Logistic Regression, Random Forest, XGBoost, 
        SVM, Neural Network.  
        × ×™×ª×Ÿ ×œ×”×©×•×•×ª ×‘×™× ×™×”× ×‘×××¦×¢×•×ª ×˜×‘×œ×ª ×“×™×¨×•×’ (Leaderboard) ×•×’×¨×¤×™× (ROC, PR).
        """)

    df_metrics = pd.DataFrame(metrics).T.reset_index().rename(columns={"index": "Model"})
    df_metrics = df_metrics.sort_values("roc_auc", ascending=False).reset_index(drop=True)
    df_metrics.insert(0, "Rank", df_metrics.index + 1)
    best_name = df_metrics.iloc[0]["Model"]
    df_metrics.loc[0, "Model"] = f"ğŸ† {best_name}"

    st.subheader("ğŸ“Š Model Ranking")
    st.dataframe(df_metrics)

    st.subheader("ğŸ† Best Model Results")
    best_row = df_metrics.iloc[0]
    st.table(pd.DataFrame(best_row).T)

    # Confusion Matrix (Plotly Heatmap)
    y_pred = safe_predict(best_model, X)
    y_pred_prob = safe_predict_proba(best_model, X)[:, 1]
    cm = confusion_matrix(y, y_pred, labels=[0, 1])
    fig = go.Figure(data=go.Heatmap(
        z=cm,
        x=["Healthy", "Parkinsonâ€™s"],
        y=["Healthy", "Parkinsonâ€™s"],
        colorscale="Oranges",
        text=cm,
        texttemplate="%{text}",
        showscale=True
    ))

    fig.update_layout(title="Confusion Matrix", xaxis_title="Predicted", yaxis_title="True")
    st.plotly_chart(fig, use_container_width=True)

    # ROC Curve
    fpr, tpr, _ = roc_curve(y, y_pred_prob)
    roc_auc = auc(fpr, tpr)
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=fpr, y=tpr, mode="lines", name=f"ROC curve (AUC={roc_auc:.2f})"))
    fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode="lines", line=dict(dash="dash"), name="Random"))
    fig.update_layout(title="ROC Curve")
    st.plotly_chart(fig, use_container_width=True)

    # Precision-Recall Curve
    precision, recall, _ = precision_recall_curve(y, y_pred_prob)
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=recall, y=precision, mode="lines", name="PR Curve"))
    fig.update_layout(title="Precision-Recall Curve", xaxis_title="Recall", yaxis_title="Precision")
    st.plotly_chart(fig, use_container_width=True)

    # Learning Curve
    st.subheader("Learning Curve â€“ Best Model")
    train_sizes, train_scores, test_scores = learning_curve(
        best_model, X, y, cv=5, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 5)
    )
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=train_sizes, y=np.mean(train_scores, axis=1),
                             mode="lines+markers", name="Train"))
    fig.add_trace(go.Scatter(x=train_sizes, y=np.mean(test_scores, axis=1),
                             mode="lines+markers", name="Validation"))
    fig.update_layout(title="Learning Curve", xaxis_title="Training Samples", yaxis_title="Score")
    st.plotly_chart(fig, use_container_width=True)

    # Cumulative Gain Curve
    st.subheader("Cumulative Gain Curve")
    gains = np.cumsum(np.sort(y_pred_prob)[::-1]) / sum(y)
    percents = np.linspace(0, 1, len(gains))
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=percents, y=gains, mode="lines", name="Model"))
    fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode="lines", name="Random", line=dict(dash="dash")))
    fig.update_layout(title="Cumulative Gain Curve", xaxis_title="Proportion of Sample", yaxis_title="Proportion of Positives")
    st.plotly_chart(fig, use_container_width=True)

    # Lift Curve
    st.subheader("Lift Curve")
    lift = gains / percents
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=percents[1:], y=lift[1:], mode="lines", name="Lift"))
    fig.update_layout(title="Lift Curve", xaxis_title="Proportion of Sample", yaxis_title="Lift")
    st.plotly_chart(fig, use_container_width=True)

    # KS Curve
    st.subheader("KS Curve")
    fpr, tpr, thresholds = roc_curve(y, y_pred_prob)
    ks_stat = max(tpr - fpr)
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=thresholds, y=tpr, mode="lines", name="TPR"))
    fig.add_trace(go.Scatter(x=thresholds, y=fpr, mode="lines", name="FPR"))
    fig.update_layout(title=f"KS Curve (KS={ks_stat:.2f})", xaxis_title="Threshold", yaxis_title="Rate")
    st.plotly_chart(fig, use_container_width=True)
    
    import io
    from reportlab.lib.pagesizes import letter
    from reportlab.pdfgen import canvas
    
    if st.button("ğŸ“„ Download Full Report (PDF)"):
        pdf_buffer = io.BytesIO()
        c = canvas.Canvas(pdf_buffer, pagesize=letter)
        c.setFont("Helvetica", 14)
        c.drawString(50, 750, "Parkinsonâ€™s ML Report")
        
        c.setFont("Helvetica", 10)
        c.drawString(50, 720, f"Last Updated: {last_updated}")
        c.drawString(50, 700, f"Best Model: {best_name}")
        c.drawString(50, 680, f"Metrics: {json.dumps(metrics[best_name], indent=2)}")
        
        c.save()
        st.download_button("ğŸ“¥ Download Report PDF", pdf_buffer.getvalue(),
                           file_name="report.pdf", mime="application/pdf")
        
    st.header("ğŸ“ˆ Graphs & Insights")
    with st.expander("ğŸŸ¦ Confusion Matrix"):
        st.markdown("""
        - **XGBoost:** ×›××¢×˜ ×•×œ× ×¤×¡×¤×¡ ×—×•×œ×™× ×××™×ª×™×™× (××¢×˜ ×××•×“ False Negatives).  
        - **Logistic Regression:** ×”×¨×‘×” False Positives (×”×ª×¨×¢×•×ª ×©×•×•×).  
        ğŸ“Œ ×¨×¤×•××™×ª: ×¢×“×™×£ ×©×™×”×™×• False Positives ×××©×¨ ×œ×¤×¡×¤×¡ ×—×•×œ×” ×××™×ª×™.  
        """)
            
    with st.expander("ğŸ“‰ ROC Curves"):
        st.markdown("""
        - **Boosting Models (XGBoost, LightGBM, CatBoost):** ×¢×§×•××•×ª ×—×“×•×ª ×××•×“, AUC ×’×‘×•×”.  
        - **Logistic Regression:** ×¤×—×•×ª ××“×•×™×§, ×§×¨×•×‘ ×™×•×ª×¨ ×œ××œ×›×¡×•×Ÿ.  
        """)
                
    with st.expander("ğŸ“Š Precision-Recall Curves"):
        st.markdown("""
        - **Boosting:** ×©××¨×• ×¢×œ Precision ×’×‘×•×” ×’× ×›××©×¨ Recall ×¢×œ×”.  
        - **KNN:** ×§×¨×¡ ×‘××”×™×¨×•×ª â†’ ×œ× ×©××¨ ×¢×œ ××™×–×•×Ÿ.
        """)
                
    with st.expander("ğŸ“ˆ Learning Curve"):
        st.markdown("""
        - **XGBoost:** ××ª×›× ×¡ ×‘×¦×•×¨×” ×™×¦×™×‘×”, ×œ×œ× Overfitting ×—××•×¨.  
        - **NeuralNet:** ×ª× ×•×“×ª×™ ×××•×“, ×¨×’×™×© ×œ×’×•×“×œ ×”×“××˜×” ×”×§×˜×Ÿ.  
        """)

# --- Tab 4: Prediction
with tab3:
    st.header("ğŸ”® Prediction")
    with st.expander("â„¹ï¸ ××” ×ª××¦××• ×›××Ÿ?"):
        st.markdown("""
        ×›××Ÿ × ×™×ª×Ÿ ×œ×‘×¦×¢ ×—×™×–×•×™ ×‘×¤×•×¢×œ:  
        - ×”×–× ×ª × ×ª×•× ×™× ×™×“× ×™×ª (×˜×¤×¡×™×)  
        - ×”×¢×œ××ª ×§×•×‘×¥ CSV  
        ×ª×§×‘×œ×• ×ª×—×–×™×ª ×”×× ×”××“× ×—×•×œ×” ××• ×‘×¨×™×, ×›×•×œ×œ ×”×¡×ª×‘×¨×•×ª.
        """)
    threshold = st.slider("Decision Threshold", 0.0, 1.0, threshold_global, 0.01)
    
    option = st.radio("Choose input type:", ["Manual Input","Upload CSV/Excel"])

    # --- Manual Input
    if option == "Manual Input":
        inputs = {col: st.number_input(col, float(X[col].mean())) for col in X.columns}
        sample = pd.DataFrame([inputs])

        if st.button("Predict Sample"):
            prob = safe_predict_proba(best_model, sample)[0, 1]
            pred = int(prob >= threshold)

            st.subheader("ğŸ§¾ Prediction Result")
            if pred == 1:
                st.markdown(f"""
                <div style="padding:15px; background-color:#ffe6e6; border-radius:10px; text-align:center">
                    <h2 style="color:#cc0000">ğŸ”´ Parkinsonâ€™s Detected</h2>
                    <p>Probability: <b>{prob*100:.1f}%</b> (Threshold={threshold:.2f})</p>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div style="padding:15px; background-color:#e6ffe6; border-radius:10px; text-align:center">
                    <h2 style="color:#009900">ğŸŸ¢ Healthy</h2>
                    <p>Probability: <b>{prob*100:.1f}%</b> (Threshold={threshold:.2f})</p>
                </div>
                """, unsafe_allow_html=True)

            # Gauge Chart
            fig = go.Figure(go.Indicator(
                mode="gauge+number",
                value=prob*100,
                title={"text": "Probability of Parkinsonâ€™s"},
                gauge={
                    "axis": {"range": [0, 100]},
                    "bar": {"color": "red" if pred == 1 else "green"},
                    "steps": [
                        {"range": [0, 30], "color": "#e6ffe6"},
                        {"range": [30, 70], "color": "#fff5e6"},
                        {"range": [70, 100], "color": "#ffe6e6"}
                    ]
                }
            ))
            st.plotly_chart(fig, use_container_width=True)

    # --- File Upload
    elif option == "Upload CSV/Excel":
        file = st.file_uploader("Upload CSV or Excel", type=["csv", "xlsx"])
        if file:
            if file.name.endswith(".csv"):
                new_df = pd.read_csv(file)
            else:
                new_df = pd.read_excel(file)

            st.write("Preview of Uploaded Data:")
            st.dataframe(new_df.head())

            probs = safe_predict_proba(best_model, new_df)[:, 1]
            preds = (probs >= threshold).astype(int)
            new_df["Probability"] = (probs*100).round(1)
            new_df["Prediction"] = preds

            # ×¢××•×“×ª ×ª×•×¦××” ×™×“×™×“×•×ª×™×ª
            new_df["Result"] = [
                f"ğŸŸ¢ Healthy ({p:.1f}%)" if pred == 0 else f"ğŸ”´ Parkinsonâ€™s ({p:.1f}%)"
                for pred, p in zip(preds, new_df["Probability"])
            ]

            st.subheader("ğŸ“Š Prediction Summary")
            summary = pd.Series(preds).value_counts().rename({0: "Healthy ğŸŸ¢", 1: "Parkinsonâ€™s ğŸ”´"})
            st.table(summary)

            st.subheader("Detailed Results")
            st.dataframe(new_df[["Result", "Probability", "Prediction"]].head(20))

            # ×”×•×¨×“×•×ª
            st.download_button(
                "ğŸ“¥ Download Predictions (CSV)",
                new_df.to_csv(index=False).encode("utf-8"),
                "predictions.csv",
                "text/csv"
            )
            new_df.to_excel("predictions.xlsx", index=False)
            with open("predictions.xlsx", "rb") as f:
                st.download_button(
                    "ğŸ“¥ Download Predictions (Excel)",
                    f,
                    "predictions.xlsx",
                    "application/vnd.ms-excel"
                )

                
# --- Tab 5: Test Evaluation
with tab5:
    st.header("ğŸ§ª Model Evaluation on External Test Set")
    with st.expander("â„¹ï¸ ××” ×ª××¦××• ×›××Ÿ?"):
        st.markdown("""
        ×›××Ÿ ××•×¦×’×™× ×”×ª×•×¦××•×ª ×•×”×‘×™×¦×•×¢×™× ×©×œ ×”××•×“×œ ×¢×œ ×¡×˜ ×”×‘×“×™×§×”.  
        ×’×¨×¤×™× ×¢×™×§×¨×™×™×:
        - ROC Curve  
        - Confusion Matrix  
        - Precision-Recall Curve  

        ×”××˜×¨×”: ×œ×”×¢×¨×™×š ×¢×“ ×›××” ×”××•×“×œ ×‘×××ª ×˜×•×‘ ×¢×œ × ×ª×•× ×™× ×©×œ× ×¨××”.
        """)

    file = st.file_uploader("Upload Test Set (CSV with 'status' column)", type=["csv"], key="testset")
    if file:
        test_df = pd.read_csv(file)
        if "status" not in test_df.columns:
            st.error("âŒ The test set must include a 'status' column with true labels (0=Healthy, 1=Parkinsonâ€™s).")
        else:
            X_test = test_df.drop("status", axis=1)
            y_true = test_df["status"]

            y_pred = safe_predict(best_model, X_test)
            y_prob = safe_predict_proba(best_model, X_test)[:, 1]

            # ğŸ“Š Metrics
            acc = accuracy_score(y_true, y_pred)
            prec = precision_score(y_true, y_pred)
            rec = recall_score(y_true, y_pred)
            f1 = f1_score(y_true, y_pred)
            auc_val = roc_auc_score(y_true, y_prob)

            st.subheader("ğŸ“Š Metrics")
            metrics_df = pd.DataFrame([{
                "Accuracy": acc,
                "Precision": prec,
                "Recall": rec,
                "F1 Score": f1,
                "ROC-AUC": auc_val
            }])
            st.dataframe(metrics_df.style.format("{:.3f}"))

            # Confusion Matrix
            cm = confusion_matrix(y_true, y_pred)
            fig = go.Figure(data=go.Heatmap(
                z=cm,
                x=["Predicted Healthy", "Predicted Parkinsonâ€™s"],
                y=["True Healthy", "True Parkinsonâ€™s"],
                colorscale="Blues",
                text=cm, texttemplate="%{text}"
            ))
            fig.update_layout(title="Confusion Matrix")
            st.plotly_chart(fig, use_container_width=True)

            # ROC Curve
            fpr, tpr, _ = roc_curve(y_true, y_prob)
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=fpr, y=tpr, mode="lines", name=f"ROC curve (AUC={auc_val:.2f})"))
            fig.add_trace(go.Scatter(x=[0,1], y=[0,1], mode="lines", line=dict(dash="dash"), name="Random"))
            fig.update_layout(title="ROC Curve", xaxis_title="False Positive Rate", yaxis_title="True Positive Rate")
            st.plotly_chart(fig, use_container_width=True)

            # Download results
            test_df["Predicted"] = y_pred
            test_df["Probability"] = y_prob
            st.download_button("ğŸ“¥ Download Predictions (CSV)", test_df.to_csv(index=False).encode("utf-8"), "test_results.csv", "text/csv")

            test_df.to_excel("test_results.xlsx", index=False)
            with open("test_results.xlsx","rb") as f:
                st.download_button("ğŸ“¥ Download Predictions (Excel)", f, "test_results.xlsx", "application/vnd.ms-excel")



# --- Tab 6: Train New Model
with tab4:
    st.header("âš¡ Train New Model")
    with st.expander("â„¹ï¸ ××” ×ª××¦××• ×›××Ÿ?"):
        st.markdown("""
        ×‘×œ×©×•× ×™×ª ×–×• ×ª×•×›×œ×• ×œ×××Ÿ ××—×“×© ××•×“×œ ×¢×œ ×”× ×ª×•× ×™× ×”×§×™×™××™×.  
        - ×‘×—×™×¨×ª ××œ×’×•×¨×™×ª×  
        - ×›×•×•× ×•×Ÿ ×¤×¨××˜×¨×™× (Grid Search)  
        - ×”×¤×¢×œ×ª ××™××•×Ÿ ××—×“×©  

        ×”××˜×¨×”: ×œ×©×¤×¨ ×‘×™×¦×•×¢×™× ××• ×œ×”×ª× ×¡×•×ª ×‘××•×“×œ×™× × ×•×¡×¤×™×.
        """)


    st.markdown("×”×¢×œ×” ×“××˜×” ×—×“×© ×œ××™××•×Ÿ, ×‘×—×¨ ××•×“×œ×™× ×•×”×’×“×¨ ×¤×¨××˜×¨×™× â€“ × ×‘×¦×¢ ×”×©×•×•××” ××•×œ ×”××•×“×œ ×”× ×•×›×—×™ ×”×˜×•×‘ ×‘×™×•×ª×¨.")

    # âœ… ×‘×—×™×¨×ª ××•×“×œ×™×
    model_choices = st.multiselect(
        "Select Models",
        ["LogisticRegression","RandomForest","SVM","KNN","XGBoost","LightGBM","CatBoost","NeuralNet"],
        default=["RandomForest","XGBoost"]
    )

    # âœ… ×¤×¨××˜×¨×™× ×œ×›×œ ××•×“×œ (keys ×™×™×—×•×“×™×™× ×œ×œ×©×•× ×™×ª ×”×–××ª)
    st.subheader("âš™ï¸ Hyperparameters")
    params = {}

    if "LogisticRegression" in model_choices:
        params["LogisticRegression"] = {
            "C": st.slider("LogReg: Regularization C", 0.01, 10.0, 1.0, 0.1, key="logreg_c_train"),
            "max_iter": st.slider("LogReg: Max Iterations", 100, 2000, 500, 100, key="logreg_iter_train")
        }

    if "RandomForest" in model_choices:
        params["RandomForest"] = {
            "n_estimators": st.slider("RF: Number of Trees", 50, 500, 200, 50, key="rf_trees_train"),
            "max_depth": st.slider("RF: Max Depth", 2, 20, 5, key="rf_depth_train"),
            "min_samples_split": st.slider("RF: Min Samples Split", 2, 20, 2, key="rf_split_train"),
            "min_samples_leaf": st.slider("RF: Min Samples Leaf", 1, 20, 1, key="rf_leaf_train")
        }

    if "XGBoost" in model_choices:
        params["XGBoost"] = {
            "learning_rate": st.slider("XGB: Learning Rate", 0.01, 0.5, 0.1, 0.01, key="xgb_lr_train"),
            "n_estimators": st.slider("XGB: Estimators", 50, 500, 200, 50, key="xgb_estimators_train"),
            "max_depth": st.slider("XGB: Max Depth", 2, 20, 6, key="xgb_depth_train"),
            "subsample": st.slider("XGB: Subsample", 0.5, 1.0, 1.0, 0.05, key="xgb_subsample_train"),
            "colsample_bytree": st.slider("XGB: Colsample by Tree", 0.5, 1.0, 1.0, 0.05, key="xgb_colsample_train")
        }

    if "LightGBM" in model_choices:
        params["LightGBM"] = {
            "n_estimators": st.slider("LGBM: Estimators", 50, 500, 200, 50, key="lgb_estimators_train"),
            "learning_rate": st.slider("LGBM: Learning Rate", 0.01, 0.5, 0.1, 0.01, key="lgb_lr_train"),
            "num_leaves": st.slider("LGBM: Num Leaves", 10, 200, 31, key="lgb_leaves_train"),
            "max_depth": st.slider("LGBM: Max Depth", -1, 20, -1, key="lgb_depth_train")
        }

    if "CatBoost" in model_choices:
        params["CatBoost"] = {
            "iterations": st.slider("CatBoost: Iterations", 100, 2000, 500, 100, key="cat_iters_train"),
            "depth": st.slider("CatBoost: Depth", 2, 12, 6, key="cat_depth_train"),
            "learning_rate": st.slider("CatBoost: Learning Rate", 0.01, 0.5, 0.1, 0.01, key="cat_lr_train")
        }

    if "SVM" in model_choices:
        params["SVM"] = {
            "C": st.slider("SVM: Regularization C", 0.01, 10.0, 1.0, 0.1, key="svm_c_train"),
            "kernel": st.selectbox("SVM: Kernel", ["rbf", "linear", "poly"], index=0, key="svm_kernel_train"),
            "gamma": st.selectbox("SVM: Gamma", ["scale", "auto"], index=0, key="svm_gamma_train")
        }

    if "KNN" in model_choices:
        params["KNN"] = {
            "n_neighbors": st.slider("KNN: Neighbors", 1, 20, 5, key="knn_neighbors_train"),
            "weights": st.selectbox("KNN: Weights", ["uniform", "distance"], index=0, key="knn_weights_train")
        }

    if "NeuralNet" in model_choices:
        params["NeuralNet"] = {
            "hidden_layer_sizes": st.text_input("NN: Hidden Layers (comma-separated)", "64,32", key="nn_layers_train"),
            "activation": st.selectbox("NN: Activation", ["relu", "tanh", "logistic"], index=0, key="nn_activation_train"),
            "max_iter": st.slider("NN: Max Iterations", 100, 2000, 500, 100, key="nn_iter_train")
        }

    # âœ… ×§×•×‘×¥ ×“××˜×” ×—×“×©
    file = st.file_uploader("Upload CSV for retraining", type=["csv"], key="newtrain")
    if file:
        new_df = pd.read_csv(file)
        st.write("ğŸ“‚ New Data Preview:", new_df.head())

        if st.button("ğŸš€ Retrain Models"):
            # ğŸŸ¢ ×©×™×œ×•×‘ ×”×“××˜×” ×”×—×“×© ×¢× ×”××§×•×¨×™
            combined_df = pd.concat([df, new_df], ignore_index=True)
            X_combined = combined_df.drop("status", axis=1)
            y_combined = combined_df["status"]

            X_train, X_test, y_train, y_test = train_test_split(
                X_combined, y_combined, test_size=0.2, random_state=42, stratify=y_combined
            )

            trained_models = {}
            metrics_comp = {}

            # ğŸŸ¢ ×œ×•×œ××ª ××™××•×Ÿ
            for m in model_choices:
                model = None

                if m == "LogisticRegression":
                    model = Pipeline([
                        ("scaler", StandardScaler()),
                        ("clf", LogisticRegression(
                            C=params[m]["C"],
                            max_iter=params[m]["max_iter"]
                        ))
                    ])
                elif m == "RandomForest":
                    model = RandomForestClassifier(
                        n_estimators=params[m]["n_estimators"],
                        max_depth=params[m]["max_depth"],
                        min_samples_split=params[m]["min_samples_split"],
                        min_samples_leaf=params[m]["min_samples_leaf"],
                        random_state=42
                    )
                elif m == "XGBoost":
                    model = xgb.XGBClassifier(
                        eval_metric="logloss",
                        n_estimators=params[m]["n_estimators"],
                        learning_rate=params[m]["learning_rate"],
                        max_depth=params[m]["max_depth"],
                        subsample=params[m]["subsample"],
                        colsample_bytree=params[m]["colsample_bytree"],
                        random_state=42
                    )
                elif m == "LightGBM":
                    model = lgb.LGBMClassifier(
                        n_estimators=params[m]["n_estimators"],
                        learning_rate=params[m]["learning_rate"],
                        num_leaves=params[m]["num_leaves"],
                        max_depth=params[m]["max_depth"],
                        random_state=42
                    )
                elif m == "CatBoost":
                    model = CatBoostClassifier(
                        iterations=params[m]["iterations"],
                        depth=params[m]["depth"],
                        learning_rate=params[m]["learning_rate"],
                        verbose=0,
                        random_state=42
                    )
                elif m == "SVM":
                    model = Pipeline([
                        ("scaler", StandardScaler()),
                        ("clf", SVC(
                            C=params[m]["C"],
                            kernel=params[m]["kernel"],
                            gamma=params[m]["gamma"],
                            probability=True
                        ))
                    ])
                elif m == "KNN":
                    model = Pipeline([
                        ("scaler", StandardScaler()),
                        ("clf", KNeighborsClassifier(
                            n_neighbors=params[m]["n_neighbors"],
                            weights=params[m]["weights"]
                        ))
                    ])
                elif m == "NeuralNet":
                    hidden_layers = tuple(map(int, params[m]["hidden_layer_sizes"].split(",")))
                    model = Pipeline([
                        ("scaler", StandardScaler()),
                        ("clf", MLPClassifier(
                            hidden_layer_sizes=hidden_layers,
                            activation=params[m]["activation"],
                            max_iter=params[m]["max_iter"],
                            random_state=42
                        ))
                    ])

                if model is not None:
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    y_proba = model.predict_proba(X_test)[:, 1]

                    acc = accuracy_score(y_test, y_pred)
                    prec = precision_score(y_test, y_pred)
                    rec = recall_score(y_test, y_pred)
                    f1 = f1_score(y_test, y_pred)
                    auc_val = roc_auc_score(y_test, y_proba)

                    trained_models[m] = model
                    metrics_comp[m] = {
                        "accuracy": acc,
                        "precision": prec,
                        "recall": rec,
                        "f1": f1,
                        "roc_auc": auc_val
                    }

            # ğŸŸ¢ ×©××™×¨×” ×‘Ö¾session_state
            st.session_state.trained_models = trained_models

            # ğŸŸ¢ ×ª×•×¦××•×ª
            st.subheader("ğŸ“Š New Training Results")
            df_comp = pd.DataFrame(metrics_comp).T.sort_values("roc_auc", ascending=False)
            df_comp.insert(0, "Rank", range(1, len(df_comp)+1))
            df_comp_display = df_comp.copy()
            df_comp_display.iloc[0, df_comp_display.columns.get_loc("Rank")] = "ğŸ† 1"
            st.dataframe(df_comp_display)

            # ğŸŸ¢ ×”×©×•×•××” ××•×œ ×”××•×“×œ ×”×™×©×Ÿ
            st.subheader("ğŸ“ˆ Comparison with Old Best Model")
            y_pred_old = safe_predict(best_model, X_test)
            y_proba_old = safe_predict_proba(best_model, X_test)[:, 1]
            old_auc = roc_auc_score(y_test, y_proba_old)

            col1, col2 = st.columns(2)
            with col1:
                st.metric("Old Best ROC-AUC", f"{old_auc:.3f}")
            with col2:
                st.metric("New Best ROC-AUC", f"{df_comp['roc_auc'].iloc[0]:.3f}")

            # ğŸŸ¢ ROC Curve comparison
            fig = go.Figure()
            fpr_old, tpr_old, _ = roc_curve(y_test, y_proba_old)
            fig.add_trace(go.Scatter(x=fpr_old, y=tpr_old, mode="lines", name="Old Best"))
            for m in df_comp.index:
                y_proba_new = trained_models[m].predict_proba(X_test)[:, 1]
                fpr_new, tpr_new, _ = roc_curve(y_test, y_proba_new)
                fig.add_trace(go.Scatter(
                    x=fpr_new, y=tpr_new, mode="lines",
                    name=f"{m} (AUC={metrics_comp[m]['roc_auc']:.2f})"
                ))
            fig.add_trace(go.Scatter(
                x=[0,1], y=[0,1], mode="lines",
                line=dict(dash="dash"), name="Random"
            ))
            st.plotly_chart(fig, use_container_width=True)

            # ğŸŸ¢ Promote option
            from datetime import datetime
            with open("assets/last_updated.txt", "w") as f:
                f.write(datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

            best_new_model = df_comp.index[0]
            if df_comp["roc_auc"].iloc[0] > old_auc:
                st.success(f"ğŸ‰ ×”××•×“×œ ×”×—×“×© {best_new_model} ×¢×“×™×£ ×¢×œ ×”××•×“×œ ×”×™×©×Ÿ!")
                if st.button("ğŸš€ Promote New Model"):
                    joblib.dump(trained_models[best_new_model], "models/best_model.joblib")
                    with open("assets/metrics.json","w") as f:
                        json.dump(metrics_comp, f)
                    st.success("âœ… New model promoted as best model!")
            else:
                st.info("×”××•×“×œ ×”×™×©×Ÿ ×¢×“×™×™×Ÿ ×¢×“×™×£. ×œ× ×¢×•×“×›×Ÿ Best Model.")

# --- Tab 7: Model History
with tab_hist:
    st.header("ğŸ•‘ Model History")
    with st.expander("â„¹ï¸ ××” ×ª××¦××• ×›××Ÿ?"):
        st.markdown("""
        ×›××Ÿ ××•×¤×™×¢ ×™×•××Ÿ ×”×”×™×¡×˜×•×¨×™×” ×©×œ ×›×œ ×”××•×“×œ×™× ×©××•×× ×• ×¢×“ ×›×”.  
        ×ª×•×›×œ×• ×œ×¨××•×ª:
        - ××™×œ×• ××•×“×œ×™× × ×‘× ×•  
        - ××ª×™  
        - ×‘××™×œ×• ×¤×¨××˜×¨×™×  
        - ××” ×”×™×• ×”×ª×•×¦××•×ª ×©×œ×”×  

        ××˜×¨×ª ×”×œ×©×•× ×™×ª: ×œ×©××•×¨ ×¢×§×™×‘×•×ª ×•× ×™×”×•×œ ×’×¨×¡××•×ª ×©×œ ×”××•×“×œ×™×.
        """)

    hist_file = "assets/model_history.csv"
    if os.path.exists(hist_file):
        hist_df = pd.read_csv(hist_file)
        st.dataframe(hist_df)
        if st.button("ğŸ”™ Rollback Last Model"):
            if len(hist_df)>1:
                prev_model = hist_df.iloc[-2]["model_path"]
                best_model = joblib.load(prev_model)
                st.session_state.best_model = best_model
                st.success("âœ… Rolled back to previous model")
    else:
        st.info("No model history found yet.")

# --- Tab 8: Explain
with tab_explain:
    st.header("ğŸ§  Model Explainability")
    with st.expander("â„¹ï¸ ××” ×ª××¦××• ×›××Ÿ?"):
        st.markdown("""
        ×‘×œ×©×•× ×™×ª ×–×• × ×™×ª×Ÿ ×œ×”×‘×™×Ÿ ××™×š ×”××•×“×œ ×§×™×‘×œ ×”×—×œ×˜×•×ª.  
        ×‘×××¦×¢×•×ª **SHAP Values**:
        - Feature Importance (×”×©×¤×¢×ª ×›×œ ×¤×™×¦'×¨)  
        - SHAP Summary Plot (×›×™×•×•×Ÿ ×”×”×©×¤×¢×” ×¢×œ ×—×™×–×•×™ ×—×•×œ×”/×‘×¨×™×)  

        ×–×”×• ×—×œ×§ ×—×©×•×‘ ×‘×¤×¨×•×™×§×˜ ×¨×¤×•××™ â€“ ×œ×“×¢×ª "×œ××”" ×”××•×“×œ ×”×—×œ×™×˜ ××” ×©×”×—×œ×™×˜.
        """)

    try:
        # ğŸ”¹ Feature Importance (×œ××•×“×œ×™× ×©×ª×•××›×™× ×‘×–×”)
        if hasattr(best_model, "feature_importances_"):
            st.subheader("ğŸ”¹ Feature Importance")
            fi = pd.DataFrame({
                "Feature": X.columns,
                "Importance": best_model.feature_importances_
            }).sort_values("Importance", ascending=False)

            fig = px.bar(fi, x="Importance", y="Feature", orientation="h", title="Feature Importance")
            st.plotly_chart(fig, use_container_width=True)

        # ğŸ”¹ SHAP (×× × ×ª××š)
        st.subheader("ğŸ”¹ SHAP Summary Plot")
        import shap
        explainer = shap.Explainer(best_model, X)
        shap_values = explainer(X)

        fig, ax = plt.subplots()
        shap.summary_plot(shap_values, X, show=False)
        st.pyplot(fig)

    except Exception as e:
        st.warning(f"SHAP not available: {e}")

        # âœ… Fallback: ×§×•×¨×œ×¦×™×” ×¤×©×•×˜×” ×¢× ×”××˜×¨×”
        st.subheader("ğŸ”¹ Correlation with Target (Fallback)")
        corr = df.corr()["status"].drop("status").sort_values(ascending=False)
        corr_df = corr.reset_index().rename(columns={"index": "Feature", "status": "Correlation"})
        fig = px.bar(corr_df, x="Correlation", y="Feature", orientation="h", title="Correlation with Target")
        st.plotly_chart(fig, use_container_width=True)
        tab_explain = st.tabs(["ğŸ§  Explainability"])[0]
        with tab_explain:
            st.header("ğŸ§  Model Explainability")
            try:
                if hasattr(best_model, "feature_importances_"):
                    importances = best_model.feature_importances_
                    feat_df = pd.DataFrame({"Feature": X.columns, "Importance": importances})
                    feat_df = feat_df.sort_values("Importance", ascending=False).head(15)
                    
                    fig = px.bar(feat_df, x="Importance", y="Feature", orientation="h", title="Top Feature Importances")
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("Feature importance not available for this model type.")
            except Exception as e:
                st.warning(f"Explainability not available: {e}")  
            st.header("ğŸ” Explainability (SHAP)")

    st.header("ğŸ” Explainability (SHAP)")
    with st.expander("â„¹ï¸ ××” ×–×” Explainability?"):
        st.markdown("""
        ×ª×—×•× ×”×‘×•×—×Ÿ ××™×š ××•×“×œ×™× ××§×‘×œ×™× ×”×—×œ×˜×•×ª.  
        ×‘×¨×¤×•××” â€“ ×©×§×™×¤×•×ª ×§×¨×™×˜×™×ª: ×¨×•×¤× ×—×™×™×‘ ×œ×“×¢×ª ×œ××” ×”××¢×¨×›×ª ×××¨×” "×—×•×œ×”".  
        """)

    with st.expander("âš™ï¸ ×”×›×œ×™ â€“ SHAP"):
        st.markdown("""
        - ××‘×•×¡×¡ ×¢×œ Shapley values (×ª×•×¨×ª ×”××©×—×§×™×).  
        - ××—×©×‘ ××ª ×”×ª×¨×•××” ×©×œ ×›×œ ××©×ª× ×” ×œ×—×™×–×•×™.  
        - × ×•×ª×Ÿ ×’× ×¡×“×¨ ×—×©×™×‘×•×ª ×•×’× ×× ×”×ª×¨×•××” ×—×™×•×‘×™×ª ××• ×©×œ×™×œ×™×ª.  
        """)

    with st.expander("ğŸ“Š ×××¦××™× ××¦×œ× ×•"):
        st.markdown("""
        - ××©×ª× ×™× ×§×¨×™×˜×™×™×: **Jitter, Shimmer, Fo, NHR**.  
        - ×–×” ×ª×•×× ×™×“×¢ ×§×œ×™× ×™ ×™×“×•×¢: ×—×•×¡×¨ ×™×¦×™×‘×•×ª ×§×•×œ×™×ª = ×¡×××Ÿ ×œ×¤×¨×§×™× ×¡×•×Ÿ.  
        """)

    with st.expander("ğŸ’¡ ×œ××” ×–×” ×—×©×•×‘?"):
        st.markdown("""
        - **×××•×Ÿ ×¨×¤×•××™:** ×¨×•×¤× ××‘×™×Ÿ ×œ××” ×”×ª×§×‘×œ×” ×”×—×œ×˜×”.  
        - **××™×ª×•×¨ ×ª×§×œ×•×ª:** ×× ×”××•×“×œ ××©×ª××© ×‘×××¤×™×™× ×™× ×œ× × ×›×•× ×™× â€“ × ×’×œ×”.  
        - **×ª×•×‘× ×•×ª ××—×§×¨×™×•×ª:** ×××¤×©×¨ ×œ×”×‘×™×Ÿ ××”× ×”×¡×× ×™× ×”×—×©×•×‘×™× ×‘×™×•×ª×¨ ×œ××—×§×¨ ×¢×ª×™×“×™.  
        """)
        


# --- Tab 9: About / ××¡×§× ×•×ª
with tab_about:
    st.header("â„¹ï¸ About / ×“×•\"×— ××¡×›×")

    with st.expander("ğŸ¯ ×¤×ª×™×—×” â€“ ×¨×§×¢ ×•××˜×¨×”"):
        st.markdown("""
        ××—×œ×ª ×¤×¨×§×™× ×¡×•×Ÿ ×”×™× ××—×œ×” × ×•×™×¨×•×œ×•×’×™×ª ××ª×§×“××ª, ×©××ª×‘×˜××ª ×‘×¢×™×§×¨ ×‘×”×¤×¨×¢×•×ª ×ª× ×•×¢×” ×•×¨×¢×™×“×•×ª ×‘×™×“×™×™×.  
        ××‘×œ ×¡×™×× ×™× ××•×§×“××™× ××•×¤×™×¢×™× ×“×•×•×§× ×‘×§×•×œ â€“ ×¨×¢×™×“×•×ª ×‘×ª×“×¨ ×”×§×•×œ, ×—×•×¡×¨ ×™×¦×™×‘×•×ª ×‘×¢×•×¦××” ×•×©×™× ×•×™×™× ×¢×“×™× ×™×.  

        ×”××˜×¨×” ×©×œ× ×• ×”×™×™×ª×” ×œ×‘×“×•×§ ×”×× ××¤×©×¨ **×œ×—×–×•×ª ××—×œ×ª ×¤×¨×§×™× ×¡×•×Ÿ ×¢×œ ×¡××š ×§×•×œ ×‘×œ×‘×“** ×‘×××¦×¢×•×ª ××œ×’×•×¨×™×ª××™× ×©×œ ×œ××™×“×ª ××›×•× ×”.  

        **×œ××” ×–×” ×—×©×•×‘?**  
        - ×›×œ×™ ×œ× ×¤×•×œ×©× ×™ â€“ ×”×§×œ×˜×ª ×§×•×œ ×¤×©×•×˜×”.  
        - ×›×œ×™ × ×’×™×© ×•×–×•×œ â€“ ×œ× ×“×•×¨×© ×¦×™×•×“ ×¨×¤×•××™ ××ª×§×“×.  
        - ×××¤×©×¨ ×’×™×œ×•×™ ××•×§×“× ×•×˜×™×¤×•×œ ××”×™×¨ ×™×•×ª×¨.  
        """)

    with st.expander("ğŸ”‘ ××” ×–×” ×¤×™×¦â€™×¨?"):
        st.markdown("""
        ×¤×™×¦â€™×¨ (Feature) ×”×•× ×××¤×™×™×Ÿ ×›××•×ª×™ ×©×œ ×”× ×ª×•× ×™× â€“ ×¢××•×“×” ×‘×˜×‘×œ×” ×©××ª××¨×ª ×ª×›×•× ×” ×©×œ ×”×§×•×œ.  

        **×“×•×’×××•×ª ××¨×›×–×™×•×ª:**  
        - **Fo (Fundamental Frequency):** ×”×ª×“×¨ ×”×‘×¡×™×¡×™ ×©×œ ×”×§×•×œ.  
        - **Fhi, Flo:** ×”×ª×“×¨ ×”×’×‘×•×” ×‘×™×•×ª×¨ ×•×”× ××•×š ×‘×™×•×ª×¨.  
        - **Jitter:** ×¨×¢×™×“×•×ª ×‘×ª×“×¨ ×”×§×•×œ â†’ ××¦×œ ×—×•×œ×™× ×’×‘×•×” ×™×•×ª×¨.  
        - **Shimmer:** ×—×•×¡×¨ ×™×¦×™×‘×•×ª ×‘×¢×•×¦××ª ×”×§×•×œ â†’ ××¦×œ ×—×•×œ×™× ×’×‘×•×” ×™×•×ª×¨.  
        - **NHR:** ×™×—×¡ ×¨×¢×©Ö¾×”×¨××•× ×™×•×ª â†’ ××¦×œ ×—×•×œ×™× ×’×‘×•×” ×™×•×ª×¨.  

        ğŸ‘‰ ×‘××™×œ×™× ×¤×©×•×˜×•×ª: ×¤×™×¦â€™×¨×™× ×”× "××“×“×™× ×¤×™×–×™×•×œ×•×’×™×™× ×©×œ ×”×§×•×œ" ×©×‘×¢×–×¨×ª× ×”××•×“×œ ×™×•×“×¢ ×œ×”×‘×“×™×œ ×‘×™×Ÿ ×—×•×œ×™× ×œ×‘×¨×™××™×.
        """)

    with st.expander("ğŸ“Š ×©×œ×‘ ×¨××©×•×Ÿ â€“ × ×™×ª×•×— ××§×“×™× (EDA)"):
        st.markdown("""
        **×œ××” ×¢×•×©×™× EDA?** ×›×“×™ ×œ×”×›×™×¨ ××ª ×”× ×ª×•× ×™×, ×œ××¦×•× ×“×¤×•×¡×™× ×•×œ×‘×“×•×§ ×× ×§×™×™××ª ×™×›×•×œ×ª ×—×™×–×•×™.  

        **××” ×¢×©×™× ×•?**  
        - ×”×™×¡×˜×•×’×¨××•×ª â€“ ×”×©×•×•××ª ×”×ª×¤×œ×’×•×ª ×©×œ jitter ×•Ö¾shimmer ××¦×œ ×—×•×œ×™× ×•×‘×¨×™××™×.  
        - Heatmap â€“ ×‘×“×™×§×ª ×§×©×¨×™× ×‘×™×Ÿ ×¤×™×¦â€™×¨×™×.  
        - PCA â€“ ×”×¦×’×ª ×”× ×ª×•× ×™× ×‘××¨×—×‘ ×“×•Ö¾×××“×™.  

        **×ª×•×¦××•×ª:**  
        - Jitter: ×—×•×œ×™× = 0.0071, ×‘×¨×™××™× = 0.0035.  
        - Shimmer: ×—×•×œ×™× = 0.035, ×‘×¨×™××™× = 0.022.  
        - Heatmap: ×§×©×¨ ×—×–×§ ×‘×™×Ÿ jitter ×œÖ¾shimmer.  
        - PCA: ×—×•×œ×™× ×•×‘×¨×™××™× ×”×•×¤×™×¢×• ×‘××–×•×¨×™× ×©×•× ×™× â†’ ×™×© ×™×›×•×œ×ª ×”×‘×—× ×” ×××™×ª×™×ª.  
        """)

    with st.expander("ğŸ¯ ×©×œ×‘ ×©× ×™ â€“ ×‘×—×™×¨×ª ×¤×™×¦â€™×¨×™×"):
        st.markdown("""
        **×œ××” ×–×” ×—×©×•×‘?**  
        - ×™×•×ª×¨ ××“×™ ×¤×™×¦â€™×¨×™× â†’ ×”××•×“×œ ××ª×‘×œ×‘×œ (Overfitting).  
        - ×¤×™×¦â€™×¨×™× ××ª×•×××™× â†’ ××™×“×¢ ×›×¤×•×œ ××™×•×ª×¨.  

        **××™×š ×‘×—×¨× ×•?**  
        - SelectKBest â€“ ×“×™×¨×•×’ ×¤×™×¦â€™×¨×™× ×œ×¤×™ ×ª×¨×•××”.  
        - RFE â€“ ×”×•×¨×“×” ×”×“×¨×’×ª×™×ª ×©×œ ×¤×™×¦â€™×¨×™× ×œ× ×—×©×•×‘×™×.  
        - VIF â€“ ×‘×“×™×§×ª ××ª×× ×‘×™×Ÿ ×¤×™×¦â€™×¨×™×.  

        **××” ××¦×× ×•?**  
        ×”×¤×™×¦â€™×¨×™× ×”×—×©×•×‘×™× ×‘×™×•×ª×¨ ×”×™×• **jitter, shimmer ×•××“×“×™ ×ª×“×¨ (Fo, Fhi, Flo)**.  
        """)

    with st.expander("ğŸ¤– ×©×œ×‘ ×©×œ×™×©×™ â€“ ×‘× ×™×™×ª ××•×“×œ×™×"):
        st.markdown("""
        ×¨×¦×™× ×• ×œ×©×œ×‘ ×‘×™×Ÿ ××•×“×œ×™× ×¤×©×•×˜×™× ×©×§×œ ×œ×”×¡×‘×™×¨ ×œ×‘×™×Ÿ ××•×“×œ×™× ×—×–×§×™×:  

        1. **Logistic Regression** â€“ ×¤×©×•×˜, ××”×™×¨, ×§×œ ×œ×”×¡×‘×¨.  
           - ×ª×•×¦××•×ª: Accuracy = 83%, Recall = 78%, ROC-AUC = 0.86.  
           - ×—×¡×¨×•×Ÿ: ××¤×¡×¤×¡ ×§×©×¨×™× ××•×¨×›×‘×™×.  

        2. **Random Forest** â€“ ×× ×¡××‘×œ ×©×œ ×¢×¦×™ ×”×—×œ×˜×”.  
           - ×ª×•×¦××•×ª: Accuracy = 87%, Recall = 91%, ROC-AUC = 0.92.  
           - ×™×ª×¨×•×Ÿ: ××¦×•×™×Ÿ ×‘×–×™×”×•×™ ×—×•×œ×™× ×××™×ª×™×™×.  
           - ×—×¡×¨×•×Ÿ: ×™×•×ª×¨ ××–×¢×§×•×ª ×©×•×•×.  

        3. **XGBoost** â€“ Boosting ××ª×§×“×.  
           - ×ª×•×¦××•×ª: Accuracy = 89%, Recall = 90%, ROC-AUC = 0.94.  
           - ×™×ª×¨×•×Ÿ: ××™×–×•×Ÿ ××¦×•×™×Ÿ ×•×‘×™×¦×•×¢×™× ×”×’×‘×•×”×™× ×‘×™×•×ª×¨.  
           - ×—×¡×¨×•×Ÿ: ×§×©×” ×œ×”×¡×‘×¨, ×“×•×¨×© ×™×•×ª×¨ ×—×™×©×•×‘.  

        4. **SVM** â€“ ××—×¤×© ×§×• ×’×‘×•×œ ××™×˜×‘×™.  
           - ×ª×•×¦××•×ª: Accuracy = 85%, Recall = 82%, ROC-AUC = 0.89.  

        5. **Neural Network (MLP)** â€“ ×¨×©×ª ×¢×¦×‘×™×ª ×¤×©×•×˜×”.  
           - ×ª×•×¦××•×ª: Accuracy = 88%, Recall = 87%, ROC-AUC = 0.93.  
           - ×™×ª×¨×•×Ÿ: ×œ×•××“ ×™×—×¡×™× ××•×¨×›×‘×™×.  
           - ×—×¡×¨×•×Ÿ: × ×•×˜×” ×œÖ¾Overfitting, ×§×©×” ×œ×”×¡×‘×¨.  
        """)

    with st.expander("âš™ï¸ ×©×œ×‘ ×¨×‘×™×¢×™ â€“ Grid Search"):
        st.markdown("""
        **××” ×–×”?**  
        Grid Search ××¨×™×¥ ××ª ×”××•×“×œ ×©×•×‘ ×•×©×•×‘ ×¢× ×¤×¨××˜×¨×™× ×©×•× ×™×, ×•×‘×•×—×¨ ××ª ×”×©×™×œ×•×‘ ×©×”×‘×™× ×œ×ª×•×¦××” ×”×˜×•×‘×” ×‘×™×•×ª×¨.  

        **××” ×©×™×¤×¨× ×• ×‘×¤×•×¢×œ?**  
        - Logistic Regression â€“ ×©×™× ×•×™ ×§×˜×Ÿ ×‘×œ×‘×“.  
        - Random Forest â€“ Recall ×¢×œ×” ×œÖ¾91% ×¢× 200 ×¢×¦×™×.  
        - XGBoost â€“ ROC-AUC ×¢×œ×” ×œÖ¾0.94 ×¢× ×¢×•××§ ×¢×¦×™× = 6 ×•Ö¾learning_rate = 0.1.  
        - Neural Network â€“ ×™×¨×™×“×” ×‘Ö¾Overfitting, ×™×¦×™×‘×•×ª ×˜×•×‘×” ×™×•×ª×¨.  

        ğŸ‘‰ Grid Search ×”×™×” ×©×œ×‘ ×§×¨×™×˜×™ ×‘×”×•×¦××ª ×”××§×¡×™××•× ××”××•×“×œ×™×.  
        """)

    with st.expander("ğŸ“ˆ ×©×œ×‘ ×—××™×©×™ â€“ ×”×¢×¨×›×ª ×‘×™×¦×•×¢×™×"):
        st.markdown("""
        **×œ××” ×—×©×•×‘ ×œ×‘×“×•×§ ×‘××¡×¤×¨ ×“×¨×›×™×?**  
        ×›×™ ×›×œ ×’×¨×£ ××¨××” ×–×•×•×™×ª ××—×¨×ª ×©×œ ×”×‘×™×¦×•×¢×™×:  

        - ROC Curve â€“ ×¢×“ ×›××” ×”××•×“×œ ×™×•×“×¢ ×œ×”×¤×¨×™×“ ×‘×™×Ÿ ×—×•×œ×™× ×œ×‘×¨×™××™×.  
        - Precision-Recall Curve â€“ ××™×–×•×Ÿ ×‘×™×Ÿ ×“×™×•×§ ×œ×™×›×•×œ×ª ×ª×¤×™×¡×”.  
        - Confusion Matrix â€“ ××¨××” ×‘×“×™×•×§ ×›××” ×—×•×œ×™× ×–×•×”×• × ×›×•×Ÿ ×•×›××” ×˜×¢×•×™×•×ª ×”×™×•.  
        - Learning Curves â€“ ×‘×•×“×§×•×ª Overfitting ××• ×¦×•×¨×š ×‘×¢×•×“ × ×ª×•× ×™×.  

        **×××¦××™× ×¢×™×§×¨×™×™×:**  
        - ROC Curve: XGBoost ×¢× ROC-AUC = 0.94 â†’ ××•×‘×™×œ ×‘×¨×•×¨.  
        - Precision-Recall: Random Forest ×”×¦×˜×™×™×Ÿ ×‘Ö¾Recall, ××‘×œ XGBoost ××™×–×Ÿ ×˜×•×‘ ×™×•×ª×¨.  
        - Confusion Matrix (XGBoost, 60 ×“×’×™××•×ª): TP = 27, TN = 27, FP = 3, FN = 3.  
        - Learning Curves: Logistic Regression ×”×ª×™×™×¦×‘ ××”×¨, Neural Network × ×˜×” ×œÖ¾Overfitting, XGBoost ×”×©×ª×¤×¨ ×¢× ×¢×•×“ × ×ª×•× ×™×.  
        """)

    with st.expander("ğŸ§  ×©×œ×‘ ×©×™×©×™ â€“ Explainability"):
        st.markdown("""
        **×œ××” ×–×” ×—×©×•×‘?**  
        ×‘×¨×¤×•××” ×—×™×™×‘×™× ×œ×”×‘×™×Ÿ *×œ××”* ×”××•×“×œ ×§×™×‘×œ ×”×—×œ×˜×”, ×•×œ× ×¨×§ ××ª ×”×ª×—×–×™×ª.  

        **××™×š ×¢×©×™× ×• ×–××ª?**  
        - Feature Importance â€“ ×“×™×¨×•×’ ×—×©×™×‘×•×ª ×¤×™×¦â€™×¨×™×.  
        - SHAP Values â€“ ××¨××™× ××™×š ×¢×¨×š ×©×œ ×›×œ ×¤×™×¦â€™×¨ ×”×©×¤×™×¢ ×¢×œ ×”×—×™×–×•×™.  

        **××” ×’×™×œ×™× ×•?**  
        - jitter â†’ ×”×¤×™×¦â€™×¨ ×”×—×©×•×‘ ×‘×™×•×ª×¨.  
        - shimmer â†’ ×©× ×™ ×‘×—×©×™×‘×•×ª×•.  
        - jitter ×’×‘×•×” â†’ ×ª×—×–×™×ª "×—×•×œ×”".  
        - jitter × ××•×š â†’ ×ª×—×–×™×ª "×‘×¨×™×".  

        ğŸ‘‰ ×”×”×¡×‘×¨×™× ×ª×××• ×™×“×¢ ×¨×¤×•××™ ×§×™×™×, ××” ×©××—×–×§ ××ª ×××•×Ÿ ×”×¨×•×¤××™× ×‘××•×“×œ.  
        """)

    with st.expander("ğŸ“Œ ××™×œ×• ×¤×™×¦â€™×¨×™× ×¢×“×™×¤×™× ×œ×©×™××•×©?"):
        st.markdown("""
        ×™×© ×©× ×™ ×¡×•×’×™× ×©×œ ×¤×™×¦â€™×¨×™× ×—×©×•×‘×™×:  

        1. **×¤×™×¦â€™×¨×™× ×‘×¡×™×¡×™×™× ×•×‘×¨×•×¨×™× ×œ×”×¡×‘×¨** â€“ ×›××• **jitter** ×•Ö¾**shimmer**.  
           - ×§×œ ×œ×”×¨××•×ª ×‘×’×¨×¤×™× ×©×—×•×œ×™× ××¦×™×’×™× ×¢×¨×›×™× ×’×‘×•×”×™× ×™×•×ª×¨.  
           - ×˜×•×‘×™× ×œ×”×¡×‘×¨ ×‘×›×™×ª×” ××• ×œ×¨×•×¤××™×.  

        2. **×¤×™×¦â€™×¨×™× ××—×•×©×‘×™× ×¢× ××ª×× ×’×‘×•×” ×œÖ¾target** â€“ ×›××• **Spread1, PPE, Spread2**.  
           - ×”× ×¤×—×•×ª ××™× ×˜×•××™×˜×™×‘×™×™×, ××‘×œ ×¡×˜×˜×™×¡×˜×™×ª ×”× ×—×–×§×™× ×™×•×ª×¨.  
           - ×”××•×“×œ ××©×ª××© ×‘×”× ×›×“×™ ×œ×©×¤×¨ ×“×™×•×§.  

        ğŸ‘‰ ×”××¡×§× ×”:  
        - ×× ×¨×•×¦×™× ×“×™×•×§ ××§×¡×™××œ×™ â†’ ×¢×“×™×£ ×œ×”×©×ª××© ×‘Ö¾Spread1, PPE ×•Ö¾Spread2.  
        - ×× ×¨×•×¦×™× ×’× ×”×¡×‘×¨ ×¤×©×•×˜ â†’ ×›×“××™ ×œ×”×•×¡×™×£ ×’× ××ª Jitter ×•Ö¾Shimmer.  
        - ×‘×¤×¨×•×™×§×˜ ×©×œ× ×• ×©×™×œ×‘× ×• ××ª ×©× ×™×”× â†’ ×›×“×™ ×©×”××•×“×œ ×™×”×™×” ×’× ×—×–×§ ×•×’× ××•×‘×Ÿ.  
        """)

    with st.expander("ğŸ’» ×©×œ×‘ ×©×‘×™×¢×™ â€“ ×”××¤×œ×™×§×¦×™×”"):
        st.markdown("""
        ×›×“×™ ×œ×”× ×’×™×© ××ª ×”×¢×‘×•×“×”, ×‘× ×™× ×• ××¤×œ×™×§×¦×™×” ×¢× 9 ×œ×©×•× ×™×•×ª:  
        1. Data & EDA â€“ ×’×¨×¤×™× ×•×¡×˜×˜×™×¡×˜×™×§×•×ª.  
        2. Dashboard â€“ KPIs ×•Ö¾Leaderboard.  
        3. Models â€“ ×¤×™×¨×•×˜ ×•×”×©×•×•××ª ××•×“×œ×™×.  
        4. Prediction â€“ ×—×™×–×•×™ ×œ×¤×™ × ×ª×•× ×™× ×—×“×©×™× ××• CSV.  
        5. Test Evaluation â€“ ROC, PR, Confusion Matrix.  
        6. Train New Model â€“ ××™××•×Ÿ ××—×“×© ×¢× Grid Search.  
        7. Model History â€“ ×”×™×¡×˜×•×¨×™×™×ª ××™××•× ×™×.  
        8. Explainability â€“ ×’×¨×¤×™ SHAP.  
        9. About â€“ ×“×•"×— ×¡×•×¤×™ ×•××¡×§× ×•×ª.  
        """)

    with st.expander("âœ… ××¡×§× ×•×ª ×¡×•×¤×™×•×ª"):
        st.markdown("""
        1. × ×™×ª×Ÿ ×œ× ×‘× ×¤×¨×§×™× ×¡×•×Ÿ ×‘×¦×•×¨×” ××“×•×™×§×ª ×¢×œ ×‘×¡×™×¡ × ×ª×•× ×™ ×§×•×œ ×‘×œ×‘×“.  
        2. **XGBoost** ×”×™×” ×”××•×“×œ ×”××•×‘×™×œ â€“ ROC-AUC = 0.94.  
        3. jitter ×•Ö¾shimmer ×”× ×”×¤×™×¦â€™×¨×™× ×”×§×¨×™×˜×™×™× ×‘×™×•×ª×¨ ×œ×”×‘× ×” ×•×”×¡×‘×¨.  
        4. Spread1, PPE ×•Ö¾Spread2 × ×ª× ×• ××ª ×”×›×•×— ×”×¡×˜×˜×™×¡×˜×™ ×”×—×–×§ ×‘×™×•×ª×¨ ×œ××•×“×œ.  
        5. Grid Search ×©×™×¤×¨ ××©××¢×•×ª×™×ª ××ª ×”××•×“×œ×™×.  
        6. ×”××¤×œ×™×§×¦×™×” ××¡×¤×§×ª ×’× ×—×™×–×•×™ ×•×’× ×”×¡×‘×¨ â€“ ×—×™×•× ×™ ×œ×©×™××•×© ×¨×¤×•××™.  
        """)

    with st.expander("âœ¨ × ×§×•×“×•×ª ××¢× ×™×™× ×•×ª"):
        st.markdown("""
        - ×’× ××•×“×œ×™× ×¤×©×•×˜×™× ×›××• Logistic Regression ×”×¦×œ×™×—×• ×œ×”×¨××•×ª ×“×¤×•×¡×™× â†’ ×¡×™××Ÿ ×©×”×§×•×œ ×”×•× ××™× ×“×™×§×˜×•×¨ ×—×–×§ ×××•×“.  
        - Random Forest ×›××¢×˜ ×•×œ× ×¤×¡×¤×¡ ×—×•×œ×™×, ××‘×œ ×™×¦×¨ ×™×•×ª×¨ ××–×¢×§×•×ª ×©×•×•×.  
        - Neural Network ×”×™×” ×§×¨×•×‘ ×œÖ¾XGBoost, ××š ×¤×—×•×ª ×™×¦×™×‘.  
        - XGBoost ×”×™×” ×”×›×™ ×××•×–×Ÿ ×•×œ×›×Ÿ × ×‘×—×¨ ×›××•×“×œ ×”××•×‘×™×œ.  
        - ×”×”×¡×‘×¨×™× ×©×œ SHAP ×ª×××• ×™×“×¢ ×§×œ×™× ×™ â†’ ××” ×©××¢×œ×” ××ª ×”×××•×Ÿ ×‘××¢×¨×›×ª.  
        """)

# --- Tab 10: Q&A
tab_qa, = st.tabs(["â“ Q&A"])

with tab_qa:
    st.header("â“ ×©××œ×•×ª ×•×ª×©×•×‘×•×ª × ×¤×•×¦×•×ª ×¢×œ ×”×¤×¨×•×™×§×˜")

    # --- ×¢×œ ×”× ×ª×•× ×™× ---
    with st.expander("ğŸ“Š ×××™×¤×” ×”×’×™×¢×• ×”× ×ª×•× ×™× ×•××™×š × ××¡×¤×•?"):
        st.markdown("""
        ×”× ×ª×•× ×™× ×”×’×™×¢×• ×Ö¾**UCI Machine Learning Repository**.  
        ×”× × ××¡×¤×• ××”×§×œ×˜×•×ª ×§×•×œ ×©×œ ×—×•×œ×™ ×¤×¨×§×™× ×¡×•×Ÿ ×•×©×œ ×× ×©×™× ×‘×¨×™××™×.  
        ××›×œ ×”×§×œ×˜×” ×”×•×¤×§×• ×¢×©×¨×•×ª ×¤×™×¦â€™×¨×™× ××ª××˜×™×™× (×›××• jitter, shimmer, PPE) ×©×ª×™××¨×• ××ª ××™×›×•×ª ×”×§×•×œ.
        """)

    with st.expander("ğŸ“Š ×œ××” ×“×•×•×§× ×§×•×œ ×•×œ× × ×ª×•× ×™× ××—×¨×™×?"):
        st.markdown("""
        ×§×•×œ ×”×•× ×›×œ×™ **×œ× ×¤×•×œ×©× ×™**, **×¤×©×•×˜** ×•Ö¾**×–×•×œ** ×œ××™×¡×•×£.  
        ××¡×¤×™×§×ª ×”×§×œ×˜×” ×§×¦×¨×”, ×•××¤×©×¨ ×œ× ×ª×— ××•×ª×” ××•×˜×•××˜×™×ª.  
        ×–×” × ×•×ª×Ÿ ×™×ª×¨×•×Ÿ ×’×“×•×œ ×¢×œ ×¤× ×™ ×‘×“×™×§×•×ª ×¨×¤×•××™×•×ª ××—×¨×•×ª, ×©×™×›×•×œ×•×ª ×œ×”×™×•×ª ×™×§×¨×•×ª ××• ×¤×•×œ×©× ×™×•×ª.  
        """)

    with st.expander("ğŸ“Š ×”×× ×”×“××˜×” ×”×™×” ×××•×–×Ÿ ×‘×™×Ÿ ×—×•×œ×™× ×œ×‘×¨×™××™×?"):
        st.markdown("""
        ×œ×. ×”×“××˜×” ×›×œ×œ **×™×•×ª×¨ ×—×•×œ×™× ×××©×¨ ×‘×¨×™××™×**.  
        ×–×” ×™×¦×¨ ×‘×¢×™×™×ª ×—×•×¡×¨ ××™×–×•×Ÿ (class imbalance).  
        ×œ×›×Ÿ ×œ× ×”×¡×ª×¤×§× ×• ×‘××“×“ Accuracy, ××œ× ×‘×—× ×• ×’× **Recall ×•Ö¾Precision** ×›×“×™ ×œ×•×•×“× ×©×”××•×“×œ ×œ× "× ×•×˜×”" ×™×•×ª×¨ ××“×™ ×œ×›×™×•×•×Ÿ ×”×—×•×œ×™×.
        """)

    with st.expander("ğŸ“Š ×”×× ×‘×“×§×ª× ×¢×¨×›×™× ×—×¡×¨×™× ××• ×¨×¢×©×™×?"):
        st.markdown("""
        ×›×Ÿ. ×‘×“×§× ×• ×©××™×Ÿ ×¢×¨×›×™× ×—×¡×¨×™× ××©××¢×•×ª×™×™×.  
        ×”×¨×¢×©×™× ×‘×”×§×œ×˜×•×ª ×›×‘×¨ ×¢×•×‘×“×• ××¨××© (pre-processing).  
        ×¢×“×™×™×Ÿ ×™×™×ª×›×Ÿ ×©×‘×“××˜×” ×××™×ª×™ ×™×”×™×• ×¨×¢×©×™× × ×•×¡×¤×™×, ×•×–×” ××ª×’×¨ ×œ××—×§×¨ ×¢×ª×™×“×™.
        """)

    with st.expander("ğŸ“Š ×”×× × ×¢×©×” × ×™×¨××•×œ (Normalization) ×œ× ×ª×•× ×™×?"):
        st.markdown("""
        ×›×Ÿ. ×—×œ×§ ××”××•×“×œ×™× (×›××• Logistic Regression, SVM, Neural Network) ×¨×’×™×©×™× ×××•×“ ×œ×¡×§×œ×•×ª ×©×•× ×•×ª.  
        ×œ×›×Ÿ ×‘×™×¦×¢× ×• **Standardization** â€“ ×›×œ ×¤×™×¦â€™×¨ ×”×•××¨ ×œ×˜×•×•×— ×××•×¦×¢ 0 ×•×¡×˜×™×™×ª ×ª×§×Ÿ 1.  
        ×–×” ×©×™×¤×¨ ××ª ×™×¦×™×‘×•×ª ×”××•×“×œ×™×.
        """)

    # --- ×¢×œ ×”×¤×™×¦'×¨×™× ---
    with st.expander("ğŸ”‘ ××” ×–×” ×¤×™×¦â€™×¨?"):
        st.markdown("""
        ×¤×™×¦â€™×¨ ×”×•× **×××¤×™×™×Ÿ ××¡×¤×¨×™ ×©×œ ×”×§×•×œ** â€“ ×¢××•×“×” ×‘×˜×‘×œ×” ×©××ª××¨×ª ××“×“ ××¡×•×™×.  
        ×œ××©×œ:  
        - **Jitter:** ×¨×¢×™×“×•×ª ×‘×ª×“×¨ ×”×§×•×œ.  
        - **Shimmer:** ×©×™× ×•×™×™× ×‘×¢×•×¦××ª ×”×§×•×œ.  
        - **Fo:** ×ª×“×¨ ×‘×¡×™×¡×™ ×©×œ ×”×§×•×œ.  
        - **PPE:** ×—×•×¡×¨ ×¡×“×™×¨×•×ª ×‘××¨×•×•×—×™ ×”×ª×“×¨.  
        - **Spread1 / Spread2:** ××“×“×™× ×¡×˜×˜×™×¡×˜×™×™× ×œ×¤×™×–×•×¨ ×”×ª×“×¨×™×.  
        """)

    with st.expander("ğŸ”‘ ×‘××™×œ×• ×¤×™×¦â€™×¨×™× ×”×©×ª××©×ª× ×‘×¤×•×¢×œ?"):
        st.markdown("""
        ×”×©×ª××©× ×• ×’× ×‘Ö¾**×¤×™×¦â€™×¨×™× ×‘×¡×™×¡×™×™× ×•×‘×¨×•×¨×™× ×œ×”×¡×‘×¨** (jitter, shimmer, Fo, Flo)  
        ×•×’× ×‘Ö¾**×¤×™×¦â€™×¨×™× ××—×•×©×‘×™× ×¢× ××ª×× ×’×‘×•×” ×œ××—×œ×”** (Spread1, PPE, Spread2).  

        ×”×©×™×œ×•×‘ × ×ª×Ÿ:  
        - ×’× **××•×“×œ ×—×–×§ ×¡×˜×˜×™×¡×˜×™×ª**.  
        - ×•×’× **×™×›×•×œ×ª ×”×¡×‘×¨ ×‘×¨×•×¨×”** ×œ×¨×•×¤××™× ×•×œ×›×™×ª×”.  
        """)

    with st.expander("ğŸ”‘ ××™×œ×• ×¤×™×¦â€™×¨×™× ×™×¦××• ×”×—×©×•×‘×™× ×‘×™×•×ª×¨?"):
        st.markdown("""
        - ××”Ö¾EDA: ×—×•×œ×™× ×”×¦×™×’×• **Jitter ×•Ö¾Shimmer ×’×‘×•×”×™× ×™×•×ª×¨** â€“ ×§×•×œ ×¤×—×•×ª ×™×¦×™×‘.  
        - ××”Ö¾Correlation: **Spread1 (0.56), PPE (0.53), Spread2 (0.45)** ×”×™×• ×”×›×™ ××ª×•×××™× ×¢× ×”××—×œ×”.  
        - ××”Ö¾Explainability (SHAP): **Jitter ×•Ö¾Shimmer** ×”×•×‘×™×œ×• ××ª ×”×—×©×™×‘×•×ª.  

        ğŸ‘‰ ×›×œ×•××¨, ×”×¤×™×¦â€™×¨×™× ×”××•×¨×›×‘×™× ×—×™×–×§×• ××ª ×”××•×“×œ ×¡×˜×˜×™×¡×˜×™×ª,  
        ×•×”×¤×™×¦â€™×¨×™× ×”×‘×¡×™×¡×™×™× ×”×™×• ×§×œ×™× ×•×‘×¨×•×¨×™× ×œ×”×¡×‘×¨.  
        """)

    # --- ×¢×œ ×”××•×“×œ×™× ---
    with st.expander("ğŸ¤– ×œ××” ×‘×—×¨×ª× ××ª ×”××•×“×œ×™× ×”××œ×•?"):
        st.markdown("""
        ×‘×—×¨× ×• ×§×©×ª ×¨×—×‘×” ×©×œ ××•×“×œ×™×:  
        - **××•×“×œ×™× ×¤×©×•×˜×™×** (Logistic Regression) â†’ ×§×œ ×œ×”×¡×‘×™×¨.  
        - **××•×“×œ×™× ×—×–×§×™×** (Random Forest, XGBoost, Neural Network) â†’ ×“×™×•×§ ×’×‘×•×”.  
        ×›×š ×™×›×•×œ× ×• ×’× ×œ×”×©×•×•×ª ×‘×™×¦×•×¢×™× ×•×’× ×œ×”×¨××•×ª ××ª ×”×¢×¨×š ×©×œ ×”××•×“×œ×™× ×”××ª×§×“××™×.
        """)

    with st.expander("ğŸ¤– ×œ××” ×œ× ×”×©×ª××©×ª× ×‘-KNN ××• Naive Bayes?"):
        st.markdown("""
        ×‘×“×§× ×• ××•×ª× ×‘×©×œ×‘×™× ×¨××©×•× ×™×™×.  
        ×”× × ×ª× ×• ×‘×™×¦×•×¢×™× ×—×œ×©×™× ×™×•×ª×¨, ×‘××™×•×—×“ ×‘Ö¾Recall.  
        ×œ×›×Ÿ ×œ× × ×›× ×¡×• ×œ×”×©×•×•××” ×”×¡×•×¤×™×ª.  
        """)

    with st.expander("ğŸ¤– ×œ××” ×—×©×•×‘ ×œ×›×œ×•×œ ×’× ××•×“×œ×™× ×¤×©×•×˜×™× ×›××• Logistic Regression?"):
        st.markdown("""
        ××•×“×œ×™× ×¤×©×•×˜×™× × ×•×ª× ×™× **Baseline** â€“ × ×§×•×“×ª ×™×™×—×•×¡.  
        ×× ××•×“×œ ××•×¨×›×‘ × ×•×ª×Ÿ ×¨×§ ×©×™×¤×•×¨ ×§×˜×Ÿ ×œ×¢×•××ª ××•×“×œ ×¤×©×•×˜, ×–×” ××¢×œ×” ×©××œ×•×ª ×× ×”××•×¨×›×‘×•×ª ××©×ª×œ××ª.  
        ×‘××§×¨×” ×©×œ× ×•, Logistic Regression × ×ª×Ÿ Accuracy ×©×œ 83% â†’ ×•×”×¨××” ×©×”×§×•×œ ×‘×××ª ××›×™×œ ××™×“×¢ ×—×–×§.  
        """)

    with st.expander("ğŸ¤– ××” ×”×™×ª×¨×•× ×•×ª ×•×”×—×¡×¨×•× ×•×ª ×©×œ XGBoost?"):
        st.markdown("""
        **×™×ª×¨×•× ×•×ª:**  
        - ×”×›×™ ××“×•×™×§: ROC-AUC = 0.94.  
        - ××™×–×•×Ÿ ××¦×•×™×Ÿ ×‘×™×Ÿ Recall ×œÖ¾Precision.  
        - ××ª××™× ×‘××™×•×—×“ ×œ× ×ª×•× ×™× ×˜×‘×œ××™×™×.  

        **×—×¡×¨×•× ×•×ª:**  
        - ×“×•×¨×© ×™×•×ª×¨ ××©××‘×™× ×—×™×©×•×‘×™×™×.  
        - ×§×©×” ×œ×”×¡×‘×¨ (Black Box) ×‘×œ×™ ×›×œ×™× ×›××• SHAP.  
        """)

    with st.expander("ğŸ¤– ×œ××” ×œ× ×”×©×ª××©×ª× ×‘×¨×©×ª×•×ª ×¢××•×§×•×ª ×™×•×ª×¨ (Deep Learning)?"):
        st.markdown("""
        ×›×™ ×”×“××˜×” ×§×˜×Ÿ ×™×—×¡×™×ª (×›××” ×××•×ª ×“×’×™××•×ª ×‘×œ×‘×“).  
        ×¨×©×ª×•×ª ×¢××•×§×•×ª ×“×•×¨×©×•×ª ×¢×©×¨×•×ª ××œ×¤×™ ×“×•×’×××•×ª ×›×“×™ ×œ×ª×ª ×™×¦×™×‘×•×ª.  
        ××—×¨×ª ×”×Ÿ × ×•×˜×•×ª ×œÖ¾Overfitting.  
        """)

    # --- ×¢×œ Grid Search ---
    with st.expander("âš™ï¸ ×œ××” ×‘×—×¨×ª× Grid Search ×•×œ× Randomized Search?"):
        st.markdown("""
        Grid Search ×‘×•×“×§ **××ª ×›×œ ×”×©×™×œ×•×‘×™× ×”××¤×©×¨×™×™×** ×©×œ ×¤×¨××˜×¨×™×.  
        ×–×” ×™×•×ª×¨ ×›×‘×“ ×—×™×©×•×‘×™×ª, ××‘×œ ×”×“××˜×” ×©×œ× ×• ×™×—×¡×™×ª ×§×˜×Ÿ ×•×œ×›×Ÿ ×–×” ×”×™×” ××¤×©×¨×™.  
        ×›×š ×§×™×‘×œ× ×• ×‘×™×˜×—×•×Ÿ ×©×œ× ×¤×¡×¤×¡× ×• ×¤×¨××˜×¨×™× ×˜×•×‘×™×.  
        """)

    # --- ×¢×œ ×”×ª×•×¦××•×ª ---
    with st.expander("ğŸ“ˆ ××” ×”××“×“ ×”×›×™ ×—×©×•×‘ ×‘×¤×¨×•×™×§×˜?"):
        st.markdown("""
        ×”××“×“ ×”×›×™ ×—×©×•×‘ ×”×•× **Recall** â€“ ×›××” ×—×•×œ×™× ×××™×ª×™×™× ×–×™×”×™× ×•.  
        ×›×™ ×‘×¨×¤×•××” ×—×©×•×‘ ×œ× ×œ×¤×¡×¤×¡ ×—×•×œ×™×.  
        """)
    with st.expander("ğŸ“ˆ ××” ×”××©××¢×•×ª ×©×œ ROC-AUC = 0.94?"):
        st.markdown("""
        ROC-AUC ××•×“×“ ××ª ×”×™×›×•×œ×ª ×œ×”×‘×“×™×œ ×‘×™×Ÿ ×—×•×œ×™× ×œ×‘×¨×™××™×.  
        ×¢×¨×š ×©×œ 0.94 ××•××¨ ×©×”××•×“×œ ××‘×“×™×œ × ×›×•× ×” ×‘Ö¾94% ××”××§×¨×™×, ×œ×œ× ×§×©×¨ ×œ×¡×£ ××¡×•×™×.  
        """)
    with st.expander("ğŸ“ˆ ××” ××¦×× ×• ×‘-Confusion Matrix?"):
        st.markdown("""
        ×‘××•×“×œ XGBoost (60 ×“×’×™××•×ª):  
        - 27 ×—×•×œ×™× ×–×•×”×• × ×›×•×Ÿ (True Positive).  
        - 27 ×‘×¨×™××™× ×–×•×”×• × ×›×•×Ÿ (True Negative).  
        - 3 ×—×•×œ×™× ×¤×¡×¤×¡× ×• (False Negative).  
        - 3 ×‘×¨×™××™× ×¡×•×•×’×• ×›×—×•×œ×™× (False Positive).  
        """)

    with st.expander("ğŸ“ˆ ××” ×œ×’×‘×™ False Positives?"):
        st.markdown("""
        ×”×™×• ×’× ×‘×¨×™××™× ×©×¡×•×•×’×• ×›×—×•×œ×™×.  
        ×–×” ×¤×—×•×ª ×—××•×¨ ×××©×¨ ×œ×¤×¡×¤×¡ ×—×•×œ×™× ×××™×ª×™×™×, ×›×™ ×‘××§×¨×” ×›×–×” ×¤×©×•×˜ × ×‘×¦×¢ ×‘×“×™×§×” ×—×•×–×¨×ª.  
        ×‘×¨×¤×•××” ×ª××™×“ ×¢×“×™×£ ×¢×•×“×£ ×¨×’×™×©×•×ª ×¢×œ ×¤× ×™ ×¤×¡×¤×•×¡.  
        """)

    # --- ×¢×œ Explainability ---
    with st.expander("ğŸ§  ×œ××” ×—×©×•×‘ ×œ×”×¡×‘×™×¨ ××ª ×”××•×“×œ?"):
        st.markdown("""
        ×‘×¨×¤×•××” ××¡×•×¨ ×œ×”×¡×ª×¤×§ ×‘×ª×—×–×™×ª "×©×—×•×¨×”".  
        ×—×™×™×‘×™× ×œ×“×¢×ª *×œ××”* ×”××•×“×œ ×§×‘×¢ ×©××™×©×”×• ×—×•×œ×” â€“ ×›×“×™ ×©×¨×•×¤× ×™×•×›×œ ×œ×¡××•×š ×¢×œ ×”×ª×•×¦××”.  
        """)

    with st.expander("ğŸ§  ××” ×”×”×‘×“×œ ×‘×™×Ÿ Feature Importance ×œ-SHAP?"):
        st.markdown("""
        - **Feature Importance:** ××“×¨×’ ×¤×™×¦â€™×¨×™× ×œ×¤×™ ×”×ª×¨×•××” ×”×›×œ×œ×™×ª ×©×œ×”×.  
        - **SHAP:** × ×•×ª×Ÿ ×”×¡×‘×¨ ×¤×¨×˜× ×™ ×œ×›×œ ×ª×—×–×™×ª ×‘×•×“×“×ª â€“ ××™×–×” ×¤×™×¦â€™×¨ ×“×—×£ ××ª ×”×—×™×–×•×™ ×•×œ×›×™×•×•×Ÿ ××™×–×”.  
        """)

    with st.expander("ğŸ§  ××” ××¦×× ×• ×‘-SHAP?"):
        st.markdown("""
        - **Jitter** â†’ ×”×¤×™×¦â€™×¨ ×”×—×©×•×‘ ×‘×™×•×ª×¨.  
        - **Shimmer** â†’ ×”×©× ×™ ×‘×—×©×™×‘×•×ª×•.  
        - jitter ×’×‘×•×” â†’ ×—×™×–×•×™ "×—×•×œ×”".  
        - jitter × ××•×š â†’ ×—×™×–×•×™ "×‘×¨×™×".  

        ×–×” ×ª×•×× ×™×“×¢ ×¨×¤×•××™ ×§×™×™× â†’ ××—×–×§ ××ª ×”×××•×Ÿ ×‘××•×“×œ.  
        """)

    # --- ×¢×œ ×”×”×©×œ×›×•×ª ×”×¨×¤×•××™×•×ª ---
    with st.expander("ğŸ¥ ×”×× ×”××•×“×œ ×”×–×” ×™×›×•×œ ×œ×©××© ×œ××‘×—×•×Ÿ ×¨×¤×•××™?"):
        st.markdown("""
        ×›×¨×’×¢ ×œ×. ×–×” ×›×œ×™ ××—×§×¨×™ ×‘×œ×‘×“.  
        ×œ×©×™××•×© ×××™×ª×™ × ×“×¨×© ××—×§×¨ ×§×œ×™× ×™ × ×¨×—×‘ ×•××™×©×•×¨ ×¨×’×•×œ×˜×•×¨×™.  
        """)

    with st.expander("ğŸ¥ ××” ×”×™×ª×¨×•×Ÿ ×©×œ ×©×™××•×© ×‘×§×•×œ ×¢×œ ×¤× ×™ ×‘×“×™×§×•×ª ××—×¨×•×ª?"):
        st.markdown("""
        ×§×•×œ ×”×•× ×¤×©×•×˜, ×–×•×œ ×•×œ× ×¤×•×œ×©× ×™.  
        ××¤×©×¨ ×œ××“×•×“ ××•×ª×• ×’× ×‘×‘×™×ª ×•×’× ×‘××¨×¤××”, ×‘×œ×™ ×¦×™×•×“ ×¨×¤×•××™ ×™×§×¨.  
        """)

    with st.expander("ğŸ¥ ×”×× ×”××•×“×œ ×™×›×•×œ ×œ×©××© ×œ××¢×§×‘ ××—×¨×™ ×”××—×œ×”?"):
        st.markdown("""
        ×›×Ÿ. ××¤×©×¨ ×œ×”×©×ª××© ×‘×• ×›×“×™ ×œ×‘×“×•×§ ××™×š ××©×ª× ×” ×”×§×•×œ ×©×œ ×—×•×œ×” ×œ××•×¨×š ×–××Ÿ.  
        ×–×” ×™×›×•×œ ×œ×¢×–×•×¨ ×œ×¢×§×•×‘ ××—×¨×™ ×”×ª×§×“××•×ª ×”××—×œ×” ××• ×ª×’×•×‘×” ×œ×˜×™×¤×•×œ.  
        """)

    with st.expander("ğŸ¥ ××” ×”×¦×¢×“ ×”×‘×?"):
        st.markdown("""
        ×œ××¡×•×£ ×“××˜×” ×’×“×•×œ ×•××’×•×•×Ÿ ×™×•×ª×¨ (×›×•×œ×œ ×§×‘×•×¦×•×ª ×’×™×œ ×©×•× ×•×ª ×•×©×¤×•×ª ×©×•× ×•×ª).  
        ×œ×”×¨×™×¥ ××—×§×¨×™× ×§×œ×™× ×™×™× ×›×“×™ ×œ×‘×“×•×§ ×× ×”××•×“×œ ××—×–×™×§ ×’× ×‘×¢×•×œ× ×”×××™×ª×™.  
        """)

    # --- ×©××œ×•×ª ×§×©×•×ª ---
    with st.expander("âš–ï¸ ×œ××” ×‘×—×¨×ª× ×‘-XGBoost ×•×œ× ×‘-Neural Network?"):
        st.markdown("""
        Neural Network × ×ª×Ÿ ×‘×™×¦×•×¢×™× ×§×¨×•×‘×™×, ××‘×œ × ×˜×” ×œÖ¾Overfitting ×•×”×™×” ×§×©×” ×œ×”×¡×‘×™×¨ ××•×ª×•.  
        XGBoost ×”×™×” ×’× ××“×•×™×§, ×’× ×™×¦×™×‘ ×•×’× × ×™×ª×Ÿ ×œ×”×¡×‘×¨ ×¢× SHAP â†’ ×•×œ×›×Ÿ × ×‘×—×¨.  
        """)

    with st.expander("âš–ï¸ ×× ×”×™×” ×œ×›× ×¢×•×“ ×–××Ÿ â€“ ××” ×”×™×™×ª× ××©×¤×¨×™×?"):
        st.markdown("""
        ×”×™×™× ×•:  
        - ××•×¡×¤×™× ×“××˜×” ×’×“×•×œ ×•××’×•×•×Ÿ ×™×•×ª×¨.  
        - ×‘×•×“×§×™× ×¨×©×ª×•×ª ×¢××•×§×•×ª ×™×•×ª×¨.  
        - ×¢×•×©×™× Cross-Validation × ×¨×—×‘.  
        """)

    with st.expander("âš–ï¸ ××” ×”××’×‘×œ×” ×”×›×™ ×’×“×•×œ×” ×‘×¤×¨×•×™×§×˜?"):
        st.markdown("""
        ×’×•×“×œ ×”×“××˜×”. ×™×© ×œ× ×• ×××•×ª ×“×’×™××•×ª ×‘×œ×‘×“, ×•×–×” ×œ× ××™×™×¦×’ ××ª ×›×œ ×”××•×›×œ×•×¡×™×™×”.  
        ×œ×›×Ÿ ×–×• ×”×•×›×—×ª ×”×™×ª×›× ×•×ª ×‘×œ×‘×“, ×œ× ×›×œ×™ ×¨×¤×•××™ ××•×›×Ÿ ×œ×©×™××•×©.  
        """)

    with st.expander("âš–ï¸ ×”×× Accuracy ×©×œ 89% ××¡×¤×™×§ ×œ×©×™××•×© ×¨×¤×•××™?"):
        st.markdown("""
        ×œ×. ×‘×¨×¤×•××” × ×“×¨×© ×“×™×•×§ ×’×‘×•×” ×‘×”×¨×‘×” (××¢×œ 95%) ×•×‘×“×™×§×•×ª ×§×œ×™× ×™×•×ª ×¨×—×‘×•×ª.  
        ××‘×œ ×›×”×•×›×—×ª ×”×™×ª×›× ×•×ª ×¨××©×•× ×™×ª â†’ ×–×” ×”×™×©×’ ××©××¢×•×ª×™ ×©××¨××” ×©×™×© ×¤×•×˜× ×¦×™××œ ×’×“×•×œ.
        """)









